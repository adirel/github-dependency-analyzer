<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="Hadoop" default="compile"
   xmlns:ivy="antlib:org.apache.ivy.ant">

  <!-- Load all the default properties, and any the user wants    -->
  <!-- to contribute (without having to type -D or edit this file -->
  <property file="${user.home}/build.properties" />
  <property file="${basedir}/build.properties" />

  <property name="Name" value="Facebook's unified version of Apache Hadoop"/>
  <property name="name" value="hadoop"/>
  <property name="version" value="0.20"/>
  <property name="final.name" value="${name}-${version}"/>
  <property name="year" value="2009"/>

  <property name="src.dir" value="${basedir}/src"/>
  <property name="core.src.dir" value="${src.dir}/core"/>
  <property name="mapred.src.dir" value="${src.dir}/mapred"/>
  <property name="hdfs.src.dir" value="${src.dir}/hdfs"/>
  <property name="native.src.dir" value="${basedir}/src/native"/>
  <property name="examples.dir" value="${basedir}/src/examples"/>
  <property name="anttasks.dir" value="${basedir}/src/ant"/>
  <property name="lib.dir" value="${basedir}/lib"/>
  <property name="conf.dir" value="${basedir}/conf"/>
  <property name="contrib.dir" value="${basedir}/src/contrib"/>
  <property name="docs.src" value="${basedir}/src/docs"/>
  <property name="changes.src" value="${docs.src}/changes"/>
  <property name="c++.src" value="${basedir}/src/c++"/>
  <property name="c++.utils.src" value="${c++.src}/utils"/>
  <property name="c++.pipes.src" value="${c++.src}/pipes"/>
  <property name="c++.examples.pipes.src" value="${examples.dir}/pipes"/>
  <property name="c++.libhdfs.src" value="${c++.src}/libhdfs"/>
  <property name="librecordio.src" value="${c++.src}/librecordio"/>
  <property name="tools.src" value="${basedir}/src/tools"/>

  <property name="xercescroot" value=""/>
  <property name="build.dir" value="${basedir}/build"/>
  <property name="build.classes" value="${build.dir}/classes"/>
  <property name="build.src" value="${build.dir}/src"/>
  <property name="build.tools" value="${build.dir}/tools"/>
  <property name="build.webapps" value="${build.dir}/webapps"/>
  <property name="build.examples" value="${build.dir}/examples"/>
  <property name="build.anttasks" value="${build.dir}/ant"/>
  <property name="build.librecordio" value="${build.dir}/librecordio"/>
  <property name="configerator.lib" location="${basedir}/src/native/lib/configerator"/>
  <property name="userGroupInfo.lib" location="${basedir}/src/native/lib/userGroupInfo"/>
  <property name="cgroup.lib" location="${basedir}/src/native/lib/cgroup"/>
  <!-- convert spaces to _ so that mac os doesn't break things -->
  <exec executable="sed" inputstring="${os.name}"
        outputproperty="nonspace.os">
     <arg value="s/ /_/g"/>
  </exec>
  <property name="build.platform"
            value="${nonspace.os}-${os.arch}-${sun.arch.data.model}"/>
  <property name="jvm.arch"
            value="${sun.arch.data.model}"/>
  <property name="build.native" value="${build.dir}/native/${build.platform}"/>
  <property name="build.c++" value="${build.dir}/c++-build/${build.platform}"/>
  <property name="build.c++.utils" value="${build.c++}/utils"/>
  <property name="build.c++.pipes" value="${build.c++}/pipes"/>
  <property name="build.c++.libhdfs" value="${build.c++}/libhdfs"/>
  <property name="build.c++.examples.pipes"
            value="${build.c++}/examples/pipes"/>
  <property name="build.docs" value="${build.dir}/docs"/>
  <property name="build.javadoc" value="${build.docs}/api"/>
  <property name="build.javadoc.dev" value="${build.docs}/dev-api"/>
  <property name="build.encoding" value="ISO-8859-1"/>
  <property name="install.c++" value="${build.dir}/c++/${build.platform}"/>
  <property name="install.c++.examples"
            value="${build.dir}/c++-examples/${build.platform}"/>

  <property name="test.src.dir" value="${basedir}/src/test"/>
  <property name="test.lib.dir" value="${basedir}/src/test/lib"/>
  <property name="test.build.dir" value="${build.dir}/test"/>
  <property name="test.generated.dir" value="${test.build.dir}/src"/>
  <property name="test.build.data" value="${test.build.dir}/data"/>
  <property name="test.cache.data" value="${test.build.dir}/cache"/>
  <property name="test.debug.data" value="${test.build.dir}/debug"/>
  <property name="test.log.dir" value="${test.build.dir}/logs"/>
  <property name="test.build.classes" value="${test.build.dir}/classes"/>
  <property name="test.build.testjar" value="${test.build.dir}/testjar"/>
  <property name="test.build.testshell" value="${test.build.dir}/testshell"/>
  <property name="test.build.extraconf" value="${test.build.dir}/extraconf"/>
  <property name="test.build.javadoc" value="${test.build.dir}/docs/api"/>
  <property name="test.build.javadoc.dev" value="${test.build.dir}/docs/dev-api"/>
  <property name="test.include" value="Test*"/>
  <property name="test.exclude" value="TestUtils"/>
  <property name="test.classpath.id" value="test.classpath"/>
  <property name="test.output" value="no"/>
  <property name="test.timeout" value="900000"/>
  <property name="test.junit.output.format" value="plain"/>
  <property name="test.junit.fork.mode" value="perTest" />
  <property name="test.junit.printsummary" value="yes" />
  <property name="test.junit.haltonfailure" value="no" />
  <property name="test.junit.maxmemory" value="1024m" />
  <property name="test.tools.input.dir" value="${basedir}/src/test/tools/data"/>
  <!-- The default user.home might have lots of dirs that will slow down
       tets that scan user.home, so allow a way to specify a custom,
       preferable empty, dir -->
  <property name="test.user.home" value="${user.home}"/>

  <property name="test.libhdfs.conf.dir" value="${c++.libhdfs.src}/tests/conf"/>
  <property name="test.libhdfs.dir" value="${test.build.dir}/libhdfs"/>

  <property name="librecordio.test.dir" value="${test.build.dir}/librecordio"/>
  <property name="web.src.dir" value="${basedir}/src/web"/>
  <property name="src.webapps" value="${basedir}/src/webapps"/>

  <property name="javadoc.link.java"
	    value="http://java.sun.com/javase/6/docs/api/"/>
  <property name="javadoc.packages" value="org.apache.hadoop.*"/>

  <property name="dist.dir" value="${build.dir}/${final.name}"/>

  <property name="javac.debug" value="on"/>
  <property name="javac.optimize" value="on"/>
  <property name="javac.deprecation" value="off"/>
  <property name="javac.version" value="1.6"/>
  <property name="javac.args" value=""/>
  <!-- NOTE: -XDignore.symbol.file removes annoying warning about use
       of proprietary sun.misc.Unsafe -->
  <property name="javac.args.warnings" value="-Xlint:unchecked -XDignore.symbol.file"/>

  <property name="clover.db.dir" location="${build.dir}/test/clover/db"/>
  <property name="clover.report.dir" location="${build.dir}/test/clover/reports"/>

  <property name="rat.reporting.classname" value="rat.Report"/>

  <property name="jdiff.build.dir" value="${build.docs}/jdiff"/>
  <property name="jdiff.xml.dir" value="${lib.dir}/jdiff"/>
  <property name="jdiff.stable" value="0.19.2"/>
  <property name="jdiff.stable.javadoc"
            value="http://hadoop.apache.org/core/docs/r${jdiff.stable}/api/"/>

  <property name="scratch.dir" value="${user.home}/tmp"/>
  <property name="svn.cmd" value="svn"/>
  <property name="grep.cmd" value="grep"/>
  <property name="patch.cmd" value="patch"/>
  <property name="make.cmd" value="make"/>

  <!-- directory that contains emma.jar and emma_ant.jar: -->
  <property name="emma.dir" value="${lib.dir}/emma"/>

  <!-- path element used by EMMA taskdef below: -->
  <path id="emma.lib" >
    <pathelement location="${emma.dir}/emma.jar" />
    <pathelement location="${emma.dir}/emma_ant.jar" />
  </path>

  <!-- this loads <emma> and <emmajava> custom tasks: -->
  <taskdef resource="emma_ant.properties" classpathref="emma.lib" />

  <target name="emma" description="turns on EMMA instrumentation/reporting" >
    <property name="emma.enabled" value="true" />
    <!-- EMMA instr class output directory: -->
    <property name="emma.instr.dir" value="${build.classes}/../instr-classes" />
    <property name="emma.coverage.dir" value="${build.classes}/../report" />
    <mkdir dir="${emma.instr.dir}" />
    <mkdir dir="${emma.coverage.dir}" />
  </target>

  <!-- task-controller properties set here -->
  <!-- Source directory from where configure is run and files are copied
  -->

  <property name="c++.task-controller.src"
    value="${basedir}/src/c++/task-controller" />
  <!-- directory where autoconf files + temporary files and src is
    stored for compilation -->
  <property name="build.c++.task-controller"
    value="${build.c++}/task-controller" />
  <!-- the default install dir is build directory override it using
   -Dtask-controller.install.dir=$HADOOP_HOME/bin -->
  <property name="task-controller.install.dir" value="${dist.dir}/bin" />
  <!-- end of task-controller properties -->

  <!-- IVY properteis set here -->
  <property name="ivy.dir" location="ivy" />
  <loadproperties srcfile="${ivy.dir}/libraries.properties"/>
  <property name="ivy.jar" location="${ivy.dir}/ivy-${ivy.version}.jar"/>
  <property name="ivy_repo_url" value="http://repo2.maven.org/maven2/org/apache/ivy/ivy/${ivy.version}/ivy-${ivy.version}.jar"/>
  <property name="ivysettings.xml" location="${ivy.dir}/ivysettings.xml" />
  <property name="ivy.org" value="org.apache.hadoop"/>
  <property name="build.dir" location="build" />
  <property name="dist.dir" value="${build.dir}/${final.name}"/>
  <property name="build.ivy.dir" location="${build.dir}/ivy" />
  <property name="build.ivy.lib.dir" location="${build.ivy.dir}/lib" />
  <property name="common.ivy.lib.dir" location="${build.ivy.lib.dir}/${ant.project.name}/common"/>
  <property name="build.ivy.report.dir" location="${build.ivy.dir}/report" />
  <property name="build.ivy.maven.dir" location="${build.ivy.dir}/maven" />
  <property name="build.ivy.maven.pom" location="${build.ivy.maven.dir}/hadoop-core-${version}.pom" />
  <property name="build.ivy.maven.jar" location="${build.ivy.maven.dir}/hadoop-core-${version}.jar" />

  <!--this is the naming policy for artifacts we want pulled down-->
  <property name="ivy.artifact.retrieve.pattern" value="${ant.project.name}/[conf]/[artifact]-[revision].[ext]"/>

  <!--this is how artifacts that get built are named-->
  <property name="ivy.publish.pattern" value="hadoop-[revision]-core.[ext]"/>
  <property name="hadoop.jar" location="${build.dir}/hadoop-${version}-core.jar" />

  <!-- jdiff.home property set -->
  <property name="jdiff.home" value="${build.ivy.lib.dir}/${ant.project.name}/jdiff"/>
  <property name="jdiff.jar" value="${jdiff.home}/jdiff-${jdiff.version}.jar"/>
  <property name="xerces.jar" value="${jdiff.home}/xerces-${xerces.version}.jar"/>

  <property name="clover.jar" location="${clover.home}/lib/clover.jar"/>
  <available property="clover.present" file="${clover.jar}" />

  <!-- check if clover reports should be generated -->
  <condition property="clover.enabled">
    <and>
        <isset property="run.clover"/>
        <isset property="clover.present"/>
    </and>
  </condition>

  <!-- Indicate is Snappy native library should be bundled with Hadoop or not -->
  <property name="bundle.snappy" value="true"/>

  <!-- Snappy native library location -->
  <property name="snappy.prefix" value="${native.src.dir}/lib/snappy"/>
  <property name="configerator.lib" value="${native.src.dir}/lib/configerator"/>
  <property name="userGroupInfo.lib" value="${native.src.dir}/lib/userGroupInfo"/>
  <property name="snappy.lib" value="${snappy.prefix}/lib"/>
  <property name="snappy.include" value="${snappy.prefix}/include"/>
  <property name="cgroup.prefix" value="${native.src.dir}/lib/cgroup"/>
  <property name="cgroup.lib" value="${native.src.dir}/lib/cgroup"/>

  <!-- the normal classpath -->
  <path id="classpath">
    <pathelement location="${build.classes}"/>
    <fileset dir="${lib.dir}">
      <include name="**/*.jar" />
      <exclude name="**/excluded/" />
    </fileset>
    <pathelement location="${conf.dir}"/>
    <path refid="ivy-common.classpath"/>
  </path>

  <!-- the unit test classpath: uses test.src.dir for configuration -->
  <path id="test.classpath">
    <pathelement location="${test.build.extraconf}"/>
    <pathelement location="${test.build.classes}" />
    <pathelement location="${test.src.dir}"/>
    <pathelement location="${build.dir}"/>
    <pathelement location="${build.examples}"/>
    <pathelement location="${build.tools}"/>
    <pathelement path="${clover.jar}"/>
    <fileset dir="${test.lib.dir}">
      <include name="**/*.jar" />
      <exclude name="**/excluded/" />
    </fileset>
    <path refid="classpath"/>
  </path>

  <!-- the cluster test classpath: uses conf.dir for configuration -->
  <path id="test.cluster.classpath">
    <path refid="classpath"/>
    <pathelement location="${test.build.classes}" />
    <pathelement location="${test.src.dir}"/>
    <pathelement location="${build.dir}"/>
  </path>

  <!-- properties dependent on the items defined above. -->
  <!--<available classname="${rat.reporting.classname}" classpathref="classpath" property="rat.present" value="true"/> -->

  <!-- ====================================================== -->
  <!-- Macro definitions                                      -->
  <!-- ====================================================== -->
  <macrodef name="macro_tar" description="Worker Macro for tar">
    <attribute name="param.destfile"/>
    <element name="param.listofitems"/>
    <sequential>
      <tar compression="gzip" longfile="gnu"
      destfile="@{param.destfile}">
      <param.listofitems/>
      </tar>
    </sequential>
  </macrodef>

  <!-- ====================================================== -->
  <!-- Stuff needed by all targets                            -->
  <!-- ====================================================== -->
  <target name="init" depends="ivy-retrieve-common">
    <mkdir dir="${build.dir}"/>
    <mkdir dir="${build.classes}"/>
    <mkdir dir="${build.tools}"/>
    <mkdir dir="${build.src}"/>
    <mkdir dir="${build.webapps}/task/WEB-INF"/>
    <mkdir dir="${build.webapps}/qjm/WEB-INF"/>
    <mkdir dir="${build.webapps}/job/WEB-INF"/>
    <mkdir dir="${build.webapps}/jmx/WEB-INF"/>
    <mkdir dir="${build.webapps}/hdfs/WEB-INF"/>
    <mkdir dir="${build.webapps}/datanode/WEB-INF"/>
    <mkdir dir="${build.webapps}/secondary/WEB-INF"/>
    <mkdir dir="${build.examples}"/>
    <mkdir dir="${build.anttasks}"/>
    <mkdir dir="${build.dir}/c++"/>

    <mkdir dir="${test.build.dir}"/>
    <mkdir dir="${test.build.classes}"/>
    <mkdir dir="${test.build.testjar}"/>
    <mkdir dir="${test.build.testshell}"/>
    <mkdir dir="${test.build.extraconf}"/>
    <tempfile property="touch.temp.file" destDir="${java.io.tmpdir}"/>
    <touch millis="0" file="${touch.temp.file}">
      <fileset dir="${conf.dir}" includes="**/*.template"/>
      <fileset dir="${contrib.dir}" includes="**/*.template"/>
    </touch>
    <delete file="${touch.temp.file}"/>
    <!-- copy all of the jsp and static files -->
    <copy todir="${build.webapps}">
      <fileset dir="${src.webapps}">
        <exclude name="**/*.jsp" />
        <exclude name="**/*.jspx" />
      </fileset>
    </copy>

    <copy todir="${conf.dir}" verbose="true">
      <fileset dir="${conf.dir}" includes="**/*.template"/>
      <mapper type="glob" from="*.template" to="*"/>
    </copy>

    <copy todir="${contrib.dir}" verbose="true">
      <fileset dir="${contrib.dir}" includes="**/*.template"/>
      <mapper type="glob" from="*.template" to="*"/>
    </copy>

    <exec executable="sh">
       <arg line="src/saveVersion.sh ${version}"/>
    </exec>
  </target>

  <!-- ====================================================== -->
  <!-- Compile the Java files                                 -->
  <!-- ====================================================== -->
  <target name="record-parser" depends="init" if="javacc.home">
      <javacc
          target="${core.src.dir}/org/apache/hadoop/record/compiler/generated/rcc.jj"
          outputdirectory="${core.src.dir}/org/apache/hadoop/record/compiler/generated"
          javacchome="${javacc.home}" />
  </target>

  <target name="compile-rcc-compiler" depends="init, record-parser">
    <javac
        includeantruntime="true"
        encoding="${build.encoding}"
        srcdir="${core.src.dir}"
        includes="org/apache/hadoop/record/compiler/**/*.java"
        destdir="${build.classes}"
        debug="${javac.debug}"
        optimize="${javac.optimize}"
        target="${javac.version}"
        source="${javac.version}"
        deprecation="${javac.deprecation}">
        <compilerarg line="${javac.args}"/>
        <classpath refid="classpath"/>
    </javac>

    <taskdef name="recordcc" classname="org.apache.hadoop.record.compiler.ant.RccTask">
      <classpath refid="classpath" />
    </taskdef>
  </target>

  <target name="compile-core-classes" depends="init, compile-rcc-compiler">
     <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
        <classpath refid="test.classpath"/>
     </taskdef>
    <!-- Compile Java files (excluding JSPs) checking warnings -->
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${core.src.dir}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="classpath"/>
    </javac>

    <copy todir="${build.classes}">
      <fileset dir="${core.src.dir}" includes="**/*.properties"/>
      <fileset dir="${core.src.dir}" includes="core-default.xml"/>
    </copy>

  </target>

  <target name="compile-mapred-classes" depends="compile-core-classes">
    <jsp-compile
     uriroot="${src.webapps}/task"
     outputdir="${build.src}"
     package="org.apache.hadoop.mapred"
     webxml="${build.webapps}/task/WEB-INF/web.xml">
    </jsp-compile>

    <jsp-compile
     uriroot="${src.webapps}/job"
     outputdir="${build.src}"
     package="org.apache.hadoop.mapred"
     webxml="${build.webapps}/job/WEB-INF/web.xml">
    </jsp-compile>

    <!-- Compile Java files (excluding JSPs) checking warnings -->
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${mapred.src.dir};${build.src}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="classpath"/>
    </javac>

    <copy todir="${build.classes}">
      <fileset dir="${mapred.src.dir}" includes="**/*.properties"/>
      <fileset dir="${mapred.src.dir}" includes="mapred-default.xml"/>
    </copy>
  </target>

  <target name="compile-hdfs-classes" depends="compile-core-classes">
    <jsp-compile
     uriroot="${src.webapps}/hdfs"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.server.namenode"
     webxml="${build.webapps}/hdfs/WEB-INF/web.xml">
    </jsp-compile>

    <jsp-compile
     uriroot="${src.webapps}/datanode"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.server.datanode"
     webxml="${build.webapps}/datanode/WEB-INF/web.xml">
    </jsp-compile>

    <jsp-compile
     uriroot="${src.webapps}/qjm"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.qjournal.server"
     webxml="${build.webapps}/qjm/WEB-INF/web.xml">
    </jsp-compile>

    <!-- Compile Java files (excluding JSPs) checking warnings -->
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${hdfs.src.dir};${build.src}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="classpath"/>
    </javac>

    <copy todir="${build.classes}">
     <fileset dir="${hdfs.src.dir}" includes="**/*.properties"/>
     <fileset dir="${hdfs.src.dir}" includes="hdfs-default.xml"/>
    </copy>
  </target>

  <target name="compile-tools" depends="init">
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${tools.src}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.tools}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="classpath"/>
    </javac>

    <copy todir="${build.tools}">
      <fileset
        dir="${tools.src}"
        includes="**/*.properties"
      />
    </copy>
  </target>

  <target name="compile-native">
    <antcall target="compile-core-native">
      <param name="compile.native" value="true"/>
    </antcall>
  </target>

  <target name="compile-core-native" depends="compile-core-classes"
          if="compile.native">

    <mkdir dir="${build.native}/lib"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/zlib"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/snappy"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/lzma"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/lz4"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/syscall"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/util"/>
    <mkdir dir="${build.native}/src/org/apache/hadoop/io/nativeio"/>

    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/io/compress/zlib"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.io.compress.zlib.ZlibCompressor" />
      <class name="org.apache.hadoop.io.compress.zlib.ZlibDecompressor" />
    </javah>

    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/io/compress/lzma"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.io.compress.lzma.LzmaCompressor" />
      <class name="org.apache.hadoop.io.compress.lzma.LzmaDecompressor" />
    </javah>

    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/io/compress/lz4"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.io.compress.lz4.Lz4Compressor" />
      <class name="org.apache.hadoop.io.compress.lz4.Lz4Decompressor" />
    </javah>

    <echo> Running javah NativeIO.java  </echo>
    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/io/nativeio"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.io.nativeio.NativeIO" />
    </javah>

    <echo> Running javah LinuxSystemCall.java  </echo>
    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/syscall"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.syscall.LinuxSystemCall" />
    </javah>

    <echo> Running javah bulk_crc32.java  </echo>
    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/util"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.util.NativeCrc32" />
    </javah>

    <echo> Running javah NativeJerasure.java  </echo>
    <javah
      classpath="${build.classes}"
      destdir="${build.native}/src/org/apache/hadoop/util"
      force="yes"
      verbose="yes"
      >
      <class name="org.apache.hadoop.util.NativeJerasure" />
    </javah>

    <exec dir="${build.native}" executable="sh" failonerror="true">
      <env key="OS_NAME" value="${os.name}"/>
      <env key="OS_ARCH" value="${os.arch}"/>
      <env key="JVM_DATA_MODEL" value="${sun.arch.data.model}"/>
      <env key="HADOOP_NATIVE_SRCDIR" value="${native.src.dir}"/>
      <arg line="${native.src.dir}/configure 
          LDFLAGS='-L${snappy.lib} -L${basedir}/nativelib/lzma -L${basedir}/nativelib/lz4 -lrt'
          CPPFLAGS='-I${snappy.include} -I${basedir}/nativelib/lzma -I${basedir}/nativelib/lz4'"/>
  	</exec>

    <javah
       classpath="${build.classes}"
       destdir="${build.native}/src/org/apache/hadoop/io/compress/snappy"
       force="yes"
       verbose="yes"
       >
      <class name="org.apache.hadoop.io.compress.snappy.SnappyCompressor"/>
      <class name="org.apache.hadoop.io.compress.snappy.SnappyDecompressor"/>
    </javah>

    <exec dir="${build.native}" executable="${make.cmd}" failonerror="true">
      <env key="OS_NAME" value="${os.name}"/>
      <env key="OS_ARCH" value="${os.arch}"/>
      <env key="JVM_DATA_MODEL" value="${sun.arch.data.model}"/>
      <env key="HADOOP_NATIVE_SRCDIR" value="${native.src.dir}"/>
    </exec>

    <delete>
      <fileset dir="${build.native}/lib" includes="libsnappy.*"/> 
    </delete>
    <copy todir="${build.native}/lib">
      <fileset dir="${snappy.lib}" includes="libsnappy.*"/>
      <fileset dir="${build.native}/src/org/apache/hadoop/io/compress/snappy/.libs/" includes="libhadoopsnappy.*"/>
    </copy>

    <copy todir="${build.native}/lib">
      <fileset dir="${userGroupInfo.lib}" includes="libGetUserGroupInfo.*"/>
    </copy>
    <copy todir="${build.native}/lib">
      <fileset dir="${cgroup.lib}" includes="libCGroupEventListener.*"/>
    </copy>

  	<exec dir="${build.native}" executable="sh" failonerror="true">
  	  <arg line="${build.native}/libtool --mode=install cp ${build.native}/lib/libhadoop.la ${build.native}/lib"/>
    </exec>
    <delete>
      <fileset dir="${build.native}/lib" includes="liblzma.so*"/>
    </delete>
    <copy file="${basedir}/nativelib/lzma/liblzma.so" tofile="${build.native}/lib/liblzma.so"/>
    <copy file="${basedir}/nativelib/lzma/liblzma.so" tofile="${build.native}/lib/liblzma.so.0"/>
    <copy file="${basedir}/nativelib/lzma/liblzma.so" tofile="${build.native}/lib/liblzma.so.5"/>
    <delete>
      <fileset dir="${build.native}/lib" includes="liblz4.so*"/>
    </delete>
    <copy file="${basedir}/nativelib/lz4/liblz4.so" tofile="${build.native}/lib/liblz4.so"/>
    <copy file="${basedir}/nativelib/lz4/liblz4.so" tofile="${build.native}/lib/liblz4.so.0"/>
    <copy file="${basedir}/nativelib/lz4/liblz4.so" tofile="${build.native}/lib/liblz4.so.5"/>
  </target>

  <target name="compile-core"
          depends="clover,compile-core-classes,compile-mapred-classes,
  	compile-hdfs-classes,compile-core-native,compile-c++"
  	description="Compile core only">
  </target>

  <target name="compile-contrib" depends="compile-core,tools-jar,compile-c++-libhdfs">
     <subant target="compile">
        <property name="version" value="${version}"/>
        <property name="javac.version" value="${javac.version}"/>
        <fileset file="${contrib.dir}/build.xml"/>
     </subant>
  </target>

  <target name="compile" depends="compile-core, compile-examples, compile-contrib, compile-ant-tasks, compile-tools, compile-core-test, compile-contrib-test" description="Compile core, contrib, all tests">
  </target>

  <target name="compile-examples"
          depends="compile-core,compile-tools,compile-c++-examples">
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${examples.dir}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.examples}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath>
        <path refid="classpath"/>
        <pathelement location="${build.tools}"/>
      </classpath>
    </javac>
  </target>

  <!-- ================================================================== -->
  <!-- Make hadoop.jar                                                     -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar" depends="compile-core" description="Make hadoop.jar">
    <tar compression="gzip" destfile="${build.classes}/bin.tgz">
      <tarfileset dir="bin" mode="755"/>
    </tar>
    <jar jarfile="${build.dir}/${final.name}-core.jar"
         basedir="${build.classes}">
      <manifest>
        <section name="org/apache/hadoop">
          <attribute name="Implementation-Title" value="Hadoop"/>
          <attribute name="Implementation-Version" value="${version}"/>
          <attribute name="Implementation-Vendor" value="Facebook"/>
        </section>
      </manifest>
      <fileset file="${conf.dir}/commons-logging.properties"/>
      <fileset file="${conf.dir}/hadoop-metrics.properties"/>
      <zipfileset dir="${build.webapps}" prefix="webapps"/>
    </jar>
  </target>

  <target name="jar-source" description="Make sources.jar">
    <jar jarfile="${build.dir}/${final.name}-sources.jar">
      <manifest>
        <section name="org/apache/hadoop">
          <attribute name="Implementation-Title" value="Hadoop"/>
          <attribute name="Implementation-Version" value="${version}"/>
          <attribute name="Implementation-Vendor" value="Facebook"/>
        </section>
      </manifest>
      <fileset dir="${src.dir}/core" includes="*/**"/>
      <fileset dir="${src.dir}/hdfs/" includes="*/**"/>
      <fileset dir="${src.dir}/mapred/" includes="*/**"/>
      <fileset dir="${src.dir}/native/src" includes="*/**"/>
    </jar>
    <subant target="jar-source">
      <property name="version" value="${version}"/>
      <fileset file="${contrib.dir}/build.xml"/>
    </subant>
  </target>

  <!-- ================================================================== -->
  <!-- Make the Hadoop examples jar.                                      -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="examples" depends="jar, compile-examples" description="Make the Hadoop examples jar.">
    <jar jarfile="${build.dir}/${final.name}-examples.jar"
         basedir="${build.examples}">
      <manifest>
        <attribute name="Main-Class"
                   value="org/apache/hadoop/examples/ExampleDriver"/>
      </manifest>
    </jar>
  </target>

  <target name="tools-jar" depends="jar, compile-tools"
          description="Make the Hadoop tools jar.">
    <jar jarfile="${build.dir}/${final.name}-tools.jar"
         basedir="${build.tools}">
      <manifest>
        <attribute name="Main-Class"
                   value="org/apache/hadoop/examples/ExampleDriver"/>
      </manifest>
    </jar>
  </target>

  <!-- ================================================================== -->
  <!-- Make the Hadoop metrics jar. (for use outside Hadoop)              -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="metrics.jar" depends="compile-core" description="Make the Hadoop metrics jar. (for use outside Hadoop)">
    <jar jarfile="${build.dir}/hadoop-metrics-${version}.jar"
         basedir="${build.classes}">
      <include name="**/metrics/**" />
      <exclude name="**/package.html" />
    </jar>
  </target>

  <target name="generate-test-records" depends="compile-rcc-compiler">
    <recordcc destdir="${test.generated.dir}">
      <fileset dir="${test.src.dir}"
	         includes="**/*.jr" />
    </recordcc>
  </target>

  <!-- ================================================================== -->
  <!-- Compile test code                                                  -->
  <!-- ================================================================== -->
  <target name="compile-core-test" depends="compile-examples, compile-tools, generate-test-records">
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${test.generated.dir}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${test.build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args}" />
      <classpath refid="test.classpath"/>
    </javac>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${test.src.dir}"
     includes="org/apache/hadoop/**/*.java"
     destdir="${test.build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="test.classpath"/>
    </javac>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${test.src.dir}/testjar"
     includes="*.java"
     destdir="${test.build.testjar}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="test.classpath"/>
    </javac>
    <delete file="${test.build.testjar}/testjob.jar"/>
    <jar jarfile="${test.build.testjar}/testjob.jar"
     basedir="${test.build.testjar}">
    </jar>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${test.src.dir}/testshell"
     includes="*.java"
     destdir="${test.build.testshell}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}"/>
      <classpath refid="test.classpath"/>
     </javac>
     <delete file="${test.build.testshell}/testshell.jar"/>
     <jar jarfile="${test.build.testshell}/testshell.jar"
      basedir="${test.build.testshell}">
     </jar>

    <delete dir="${test.cache.data}"/>
    <mkdir dir="${test.cache.data}"/>
    <delete dir="${test.debug.data}"/>
    <mkdir dir="${test.debug.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/testscript.txt" todir="${test.debug.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.txt" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/io/compress/snappy/testsnappy.txt" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.jar" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.zip" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tar" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tgz" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tar.gz" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/sharedTest1/sharedTest.txt" tofile="${test.cache.data}/sharedTest1/sharedTest.txt"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/sharedTest1/sharedTest.txt" tofile="${test.cache.data}/sharedTest1/sharedTest2.txt"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/sharedTest2/sharedTest.txt" todir="${test.cache.data}/sharedTest2"/>
    <copy file="${test.src.dir}/org/apache/hadoop/mapred/sharedTest1/sharedTest.zip" todir="${test.cache.data}/sharedTest1"/>
    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/hadoop-26-dfs-dir.tgz" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/hadoop-dfs-dir.txt" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/cli/testConf.xml" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data15bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data30bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data60bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data120bytes" todir="${test.cache.data}"/>
  </target>

  <!-- ================================================================== -->
  <!-- Make hadoop-test.jar                                               -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar-test" depends="compile-core-test" description="Make hadoop-test.jar">
    <jar jarfile="${build.dir}/${final.name}-test.jar"
         basedir="${test.build.classes}">
         <manifest>
           <attribute name="Main-Class"
                      value="org/apache/hadoop/test/AllTestDriver"/>
          <section name="org/apache/hadoop">
            <attribute name="Implementation-Title" value="Hadoop"/>
            <attribute name="Implementation-Version" value="${version}"/>
            <attribute name="Implementation-Vendor" value="Facebook"/>
          </section>
         </manifest>
    </jar>
  </target>

  <!-- ================================================================== -->
  <!-- Run unit tests                                                     -->
  <!-- ================================================================== -->
  <target name="test-core" depends="jar-test" description="Run core unit tests">

    <delete dir="${test.build.data}"/>
    <mkdir dir="${test.build.data}"/>
    <delete dir="${test.log.dir}"/>
    <mkdir dir="${test.log.dir}"/>
  	<copy file="${test.src.dir}/hadoop-policy.xml"
  	  todir="${test.build.extraconf}" />

    <emma enabled="${emma.enabled}">
      <instr instrpath="${build.classes}"
             destdir="${emma.instr.dir}"
             metadatafile="${emma.coverage.dir}/metadata.emma"
             merge="true"/>
    </emma>

    <junit showoutput="${test.output}"
      printsummary="${test.junit.printsummary}"
      haltonfailure="${test.junit.haltonfailure}"
      fork="yes"
      forkmode="${test.junit.fork.mode}"
      maxmemory="${test.junit.maxmemory}"
      dir="${basedir}" timeout="${test.timeout}"
      errorProperty="tests.failed" failureProperty="tests.failed">

      <jvmarg value="-Demma.coverage.out.file=${emma.coverage.dir}/coverage.emma"/>

      <sysproperty key="test.build.data" value="${test.build.data}"/>
      <sysproperty key="test.tools.input.dir" value="${test.tools.input.dir}"/>
      <sysproperty key="test.cache.data" value="${test.cache.data}"/>
      <sysproperty key="test.debug.data" value="${test.debug.data}"/>
      <sysproperty key="hadoop.log.dir" value="${test.log.dir}"/>
      <sysproperty key="test.src.dir" value="${test.src.dir}"/>
    	<sysproperty key="taskcontroller-path" value="${taskcontroller-path}"/>
    	<sysproperty key="taskcontroller-user" value="${taskcontroller-user}"/>
      <sysproperty key="test.build.extraconf" value="${test.build.extraconf}" />
      <sysproperty key="hadoop.policy.file" value="hadoop-policy.xml"/>
      <sysproperty key="java.library.path"
        value="${build.native}/lib:${lib.dir}/native/${build.platform}:${snappy.lib}:${configerator.lib}:${cgroup.lib}:{userGroupInfo.lib}"/>
      <sysproperty key="install.c++.examples" value="${install.c++.examples}"/>
      <sysproperty key="user.home" value="${test.user.home}"/>
      <env key="LD_LIBRARY_PATH" value="${build.native}/lib${path.separator}${env.LD_LIBRARY_PATH}"/>
      <!-- set io.compression.codec.lzo.class in the child jvm only if it is set -->
	  <syspropertyset dynamic="no">
		  <propertyref name="io.compression.codec.lzo.class"/>
	  </syspropertyset>
      <!-- set compile.c++ in the child jvm only if it is set -->
      <syspropertyset dynamic="no">
         <propertyref name="compile.c++"/>
      </syspropertyset>
      <classpath>
        <pathelement location="${emma.instr.dir}" />
        <path refid="test.classpath" />
        <path refid="emma.lib" />
      </classpath>
      <formatter type="${test.junit.output.format}" />
      <batchtest todir="${test.build.dir}" unless="testcase">
        <fileset dir="${test.src.dir}"
	         includes="**/${test.include}.java"
		 excludes="**/${test.exclude}.java" />
      </batchtest>
      <batchtest todir="${test.build.dir}" if="testcase">
        <fileset dir="${test.src.dir}" includes="**/${testcase}.java"/>
      </batchtest>
    </junit>

    <emma enabled="${emma.enabled}">
      <report>
        <sourcepath>
          <dirset dir="${src.dir}" >
            <include name="core" /> 
            <include name="hdfs" /> 
            <include name="mapred" /> 
          </dirset>
        </sourcepath>

        <fileset dir="${emma.coverage.dir}">
          <include name="*.emma" />
        </fileset>
        <txt outfile="${emma.coverage.dir}/coverage.txt"/>
        <html outfile="${emma.coverage.dir}/coverage.html"/>
      </report>
    </emma>

    <fail if="tests.failed">Tests failed!</fail>
  </target>

  <target name="test-contrib" depends="compile, compile-core-test" description="Run contrib unit tests">
    <subant target="test">
       <property name="version" value="${version}"/>
       <fileset file="${contrib.dir}/build.xml"/>
    </subant>
  </target>

  <target name="compile-contrib-test" depends="compile-core, compile-contrib, compile-core-test" description="Compile contrib unit tests">
    <subant target="compile-test">
       <property name="version" value="${version}"/>
       <fileset file="${contrib.dir}/build.xml"/>
    </subant>
  </target>

  <target name="test" depends="test-core, test-contrib" description="Run core, contrib unit tests">
  </target>

  <!-- Run all unit tests, not just Test*, and use non-test configuration. -->
  <target name="test-cluster" description="Run all unit tests, not just Test*, and use non-test configuration.">
    <antcall target="test">
      <param name="test.include" value="*"/>
      <param name="test.classpath.id" value="test.cluster.classpath"/>
    </antcall>
  </target>

  <!-- Run core hdfs tests -->
  <target name="test-hdfs" depends="compile" description="Run core HDFS tests.">
    <subant target="test-core" failonerror="false">
      <property name="test.exclude" value="**/mapred*/**/Test*"/>
      <property name="test.classpath.id" value="test.cluster.classpath"/>
      <fileset file="build.xml"/>
    </subant>
    <subant target="test-hdfs">
       <property name="version" value="${version}"/>
       <fileset file="${contrib.dir}/build.xml"/>
    </subant>
  </target>

  <target name="nightly" depends="test, tar">
  </target>

  <!-- ================================================================== -->
  <!-- Run optional third-party tool targets                              -->
  <!-- ================================================================== -->
  <target name="checkstyle" depends="ivy-retrieve-checkstyle,check-for-checkstyle" if="checkstyle.present" description="Run optional third-party tool targets">
       <taskdef resource="checkstyletask.properties">
         <classpath refid="checkstyle-classpath"/>
       </taskdef>

	<mkdir dir="${test.build.dir}"/>

  	<checkstyle config="${test.src.dir}/checkstyle.xml"
  		failOnViolation="false">
      <fileset dir="${core.src.dir}" includes="**/*.java" excludes="**/generated/**"/>
      <fileset dir="${mapred.src.dir}" includes="**/*.java" excludes="**/generated/**"/>
      <fileset dir="${hdfs.src.dir}" includes="**/*.java" excludes="**/generated/**"/>
      <formatter type="xml" toFile="${test.build.dir}/checkstyle-errors.xml"/>
  	</checkstyle>

  	<xslt style="${test.src.dir}/checkstyle-noframes-sorted.xsl"
        in="${test.build.dir}/checkstyle-errors.xml"
        out="${test.build.dir}/checkstyle-errors.html"/>
  </target>

  <target name="check-for-checkstyle">
    <available property="checkstyle.present" resource="checkstyletask.properties">
       <classpath refid="checkstyle-classpath"/>
    </available>
  </target>

 <property name="findbugs.home" value=""/>
  <target name="findbugs" depends="check-for-findbugs, tar" if="findbugs.present" description="Run findbugs if present">
    <property name="findbugs.out.dir" value="${test.build.dir}/findbugs"/>
    <property name="findbugs.exclude.file" value="${test.src.dir}/findbugsExcludeFile.xml"/>
    <property name="findbugs.report.htmlfile" value="${findbugs.out.dir}/hadoop-findbugs-report.html"/>
    <property name="findbugs.report.xmlfile" value="${findbugs.out.dir}/hadoop-findbugs-report.xml"/>
    <taskdef name="findbugs" classname="edu.umd.cs.findbugs.anttask.FindBugsTask"
        classpath="${findbugs.home}/lib/findbugs-ant.jar" />

        <mkdir dir="${findbugs.out.dir}"/>

    <findbugs home="${findbugs.home}" output="xml:withMessages"
        outputFile="${findbugs.report.xmlfile}" effort="max"
        excludeFilter="${findbugs.exclude.file}" jvmargs="-Xmx512M">
      <auxClasspath>
        <fileset dir="${lib.dir}">
          <include name="**/*.jar"/>
        </fileset>
        <fileset dir="${build.ivy.lib.dir}/${ant.project.name}/common">
          <include name="**/*.jar"/>
        </fileset>
      </auxClasspath>
      <sourcePath path="${core.src.dir}"/>
      <sourcePath path="${mapred.src.dir}"/>
      <sourcePath path="${hdfs.src.dir}"/>
      <sourcePath path="${examples.dir}" />
      <sourcePath path="${tools.src}" />
      <sourcePath path="${basedir}/src/contrib/streaming/src/java" />
      <class location="${basedir}/build/${final.name}-core.jar" />
      <class location="${basedir}/build/${final.name}-examples.jar" />
      <class location="${basedir}/build/${final.name}-tools.jar" />
      <class location="${basedir}/build/contrib/streaming/${final.name}-streaming.jar" />
    </findbugs>

        <xslt style="${findbugs.home}/src/xsl/default.xsl"
        in="${findbugs.report.xmlfile}"
        out="${findbugs.report.htmlfile}"/>
  </target>

  <target name="check-for-findbugs">
    <available property="findbugs.present"
        file="${findbugs.home}/lib/findbugs.jar" />
  </target>


  <!-- ================================================================== -->
  <!-- Documentation                                                      -->
  <!-- ================================================================== -->

  <target name="docs" depends="forrest.check" description="Generate forrest-based documentation. To use, specify -Dforrest.home=&lt;base of Apache Forrest installation&gt; on the command line." if="forrest.home">
    <exec dir="${docs.src}" executable="${forrest.home}/bin/forrest"
	  failonerror="true">
      <env key="JAVA_HOME" value="${java5.home}"/>
    </exec>
    <copy todir="${build.docs}">
      <fileset dir="${docs.src}/build/site/" />
    </copy>
    <copy file="${docs.src}/releasenotes.html" todir="${build.docs}"/>
    <style basedir="${core.src.dir}" destdir="${build.docs}"
           includes="core-default.xml" style="conf/configuration.xsl"/>
    <style basedir="${hdfs.src.dir}" destdir="${build.docs}"
           includes="hdfs-default.xml" style="conf/configuration.xsl"/>
    <style basedir="${mapred.src.dir}" destdir="${build.docs}"
           includes="mapred-default.xml" style="conf/configuration.xsl"/>
    <antcall target="changes-to-html"/>
  </target>

  <target name="forrest.check" unless="forrest.home" depends="java5.check">
    <fail message="'forrest.home' is not defined. Please pass -Dforrest.home=&lt;base of Apache Forrest installation&gt; to Ant on the command-line." />
  </target>

  <target name="java5.check" unless="java5.home">
    <fail message="'java5.home' is not defined.  Forrest requires Java 5.  Please pass -Djava5.home=&lt;base of Java 5 distribution&gt; to Ant on the command-line." />
  </target>

  <target name="javadoc-dev" description="Generate javadoc for hadoop developers">
    <mkdir dir="${build.javadoc.dev}"/>
    <javadoc
      overview="${core.src.dir}/overview.html"
      packagenames="org.apache.hadoop.*"
      destdir="${build.javadoc.dev}"
      author="true"
      version="true"
      use="true"
      windowtitle="${Name} ${version} API"
      doctitle="${Name} ${version} Developer API"
      bottom="This release is based on the Facebook's Distribution of Hadoop based on hadoop-0.20 &lt;br>Copyright &amp;copy; ${year} The Apache Software Foundation."
      >
        <packageset dir="${core.src.dir}"/>
        <packageset dir="${mapred.src.dir}"/>
        <packageset dir="${hdfs.src.dir}"/>
    	<packageset dir="${examples.dir}"/>

    	<packageset dir="src/contrib/streaming/src/java"/>
    	<packageset dir="src/contrib/data_join/src/java"/>
    	<packageset dir="src/contrib/index/src/java"/>

        <link href="${javadoc.link.java}"/>

        <classpath >
          <path refid="classpath" />
          <fileset dir="src/contrib/">
            <include name="*/lib/*.jar" />
          </fileset>
          <pathelement path="${java.class.path}"/>
        </classpath>

    	<group title="Core" packages="org.apache.*"/>
    	<group title="Examples" packages="org.apache.hadoop.examples*"/>

       <group title="contrib: Streaming" packages="org.apache.hadoop.streaming*"/>
       <group title="contrib: DataJoin" packages="org.apache.hadoop.contrib.utils.join*"/>
       <group title="contrib: Index" packages="org.apache.hadoop.contrib.index*"/>

    </javadoc>
  </target>

  <target name="javadoc" depends="compile, ivy-retrieve-javadoc" description="Generate javadoc">
    <mkdir dir="${build.javadoc}"/>
    <javadoc
      overview="${core.src.dir}/overview.html"
      packagenames="org.apache.hadoop.*"
      destdir="${build.javadoc}"
      author="true"
      version="true"
      use="true"
      windowtitle="${Name} ${version} API"
      doctitle="${Name} ${version} API"
      bottom="This release is based on the Facebook's version of Hadoop.&lt;br>Copyright &amp;copy; ${year} The Apache Software Foundation."
      >
        <packageset dir="${core.src.dir}"/>
        <packageset dir="${mapred.src.dir}"/>
    	<packageset dir="${examples.dir}"/>
    	<packageset dir="${hdfs.src.dir}"/>
    	<packageset dir="src/contrib/highavailability/src/java"/>
    	<packageset dir="src/contrib/raid/src/java"/>

    	<packageset dir="src/contrib/streaming/src/java"/>
    	<packageset dir="src/contrib/data_join/src/java"/>
    	<packageset dir="src/contrib/index/src/java"/>
	<packageset dir="src/contrib/failmon/src/java/"/>

        <link href="${javadoc.link.java}"/>

        <classpath >
          <path refid="classpath" />
          <fileset dir="src/contrib/">
            <include name="*/lib/*.jar" />
          </fileset>
          <path refid="javadoc-classpath"/>
          <pathelement path="${java.class.path}"/>
          <pathelement location="${build.tools}"/>
        </classpath>

    	<group title="Core" packages="org.apache.*"/>
    	<group title="Examples" packages="org.apache.hadoop.examples*"/>

       <group title="contrib: Streaming" packages="org.apache.hadoop.streaming*"/>
       <group title="contrib: DataJoin" packages="org.apache.hadoop.contrib.utils.join*"/>
       <group title="contrib: Index" packages="org.apache.hadoop.contrib.index*"/>
       <group title="contrib: FailMon" packages="org.apache.hadoop.contrib.failmon*"/>
    </javadoc>
    <jar jarfile="${build.dir}/${final.name}-javadoc.jar">
      <fileset dir="${build.javadoc}" includes="**/*"/>
    </jar>
  </target>

  <target name="api-xml" depends="ivy-retrieve-jdiff,javadoc,write-null">
    <javadoc>
       <doclet name="jdiff.JDiff"
               path="${jdiff.jar}:${xerces.jar}">
         <param name="-apidir" value="${jdiff.xml.dir}"/>
         <param name="-apiname" value="hadoop ${version}"/>
       </doclet>
       <packageset dir="src/core"/>
       <packageset dir="src/mapred"/>
       <packageset dir="src/tools"/>
       <classpath >
         <path refid="classpath" />
         <path refid="jdiff-classpath" />
         <pathelement path="${java.class.path}"/>
       </classpath>
    </javadoc>
  </target>

  <target name="write-null">
	<exec executable="touch">
	   <arg value="${jdiff.home}/Null.java"/>
        </exec>
  </target>

  <target name="api-report" depends="ivy-retrieve-jdiff,api-xml">
    <mkdir dir="${jdiff.build.dir}"/>
    <javadoc sourcepath="src/core,src/hdfs,src,mapred,src/tools"
             destdir="${jdiff.build.dir}"
             sourceFiles="${jdiff.home}/Null.java">
       <doclet name="jdiff.JDiff"
               path="${jdiff.jar}:${xerces.jar}">
         <param name="-oldapi" value="hadoop ${jdiff.stable}"/>
         <param name="-newapi" value="hadoop ${version}"/>
         <param name="-oldapidir" value="${jdiff.xml.dir}"/>
         <param name="-newapidir" value="${jdiff.xml.dir}"/>
         <param name="-javadocold" value="${jdiff.stable.javadoc}"/>
         <param name="-javadocnew" value="../../api/"/>
         <param name="-stats"/>
       </doclet>
       <classpath >
         <path refid="classpath" />
         <path refid="jdiff-classpath"/>
         <pathelement path="${java.class.path}"/>
       </classpath>
    </javadoc>
  </target>

  <target name="changes-to-html" description="Convert CHANGES.txt into an html file">
    <mkdir dir="${build.docs}"/>
    <exec executable="perl" input="CHANGES.txt" output="${build.docs}/changes.html" failonerror="true">
      <arg value="${changes.src}/changes2html.pl"/>
    </exec>
    <copy todir="${build.docs}">
      <fileset dir="${changes.src}" includes="*.css"/>
    </copy>
  </target>

  <!-- ================================================================== -->
  <!-- D I S T R I B U T I O N                                            -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="package" depends="compile, jar, javadoc, docs, api-report, examples, tools-jar, jar-test, ant-tasks, package-librecordio"
	  description="Build distribution">
    <mkdir dir="${dist.dir}"/>
    <mkdir dir="${dist.dir}/lib"/>
    <mkdir dir="${dist.dir}/contrib"/>
    <mkdir dir="${dist.dir}/bin"/>
    <mkdir dir="${dist.dir}/docs"/>
    <mkdir dir="${dist.dir}/docs/api"/>
    <mkdir dir="${dist.dir}/docs/jdiff"/>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false" flatten="true">
      <fileset dir="${common.ivy.lib.dir}"/>
    </copy>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false">
      <fileset dir="lib">
        <exclude name="**/native/**"/>
      </fileset>
    </copy>

  	<exec dir="${dist.dir}" executable="sh" failonerror="true">
	  <env key="BASE_NATIVE_LIB_DIR" value="${lib.dir}/native"/>
	  <env key="BUILD_NATIVE_DIR" value="${build.dir}/native"/>
	  <env key="DIST_LIB_DIR" value="${dist.dir}/lib/native"/>
    <env key="BUNDLE_SNAPPY_LIB" value="${bundle.snappy}"/>
    <env key="SNAPPY_LIB_DIR" value="${snappy.prefix}/lib"/>
	  <arg line="${native.src.dir}/packageNativeHadoop.sh"/>
    </exec>

    <subant target="package">
      <!--Pass down the version in case its needed again and the target
      distribution directory so contribs know where to install to.-->
      <property name="version" value="${version}"/>
      <property name="dist.dir" value="${dist.dir}"/>
      <fileset file="${contrib.dir}/build.xml"/>
    </subant>

    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapps}"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset file="${build.dir}/${final.name}-*.jar"/>
    </copy>

    <copy todir="${dist.dir}/bin">
      <fileset dir="bin"/>
    </copy>

    <copy todir="${dist.dir}/conf">
      <fileset dir="${conf.dir}" excludes="**/*.template"/>
    </copy>

    <copy todir="${dist.dir}/docs">
      <fileset dir="${build.docs}"/>
    </copy>

    <copy file="ivy.xml" tofile="${dist.dir}/ivy.xml"/>

    <copy todir="${dist.dir}/ivy">
      <fileset dir="ivy"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset dir=".">
        <include name="*.txt" />
      </fileset>
    </copy>

    <copy todir="${dist.dir}/src" includeEmptyDirs="true">
      <fileset dir="src" excludes="**/*.template **/docs/build/**/*"/>
    </copy>

    <copy todir="${dist.dir}/c++" includeEmptyDirs="false">
      <fileset dir="${build.dir}/c++"/>
    </copy>

    <copy todir="${dist.dir}/" file="build.xml"/>

    <chmod perm="ugo+x" file="${dist.dir}/src/native/configure"/>
    <chmod perm="ugo+x" type="file" parallel="false">
        <fileset dir="${dist.dir}/bin"/>
        <fileset dir="${dist.dir}/src/contrib/">
          <include name="*/bin/*" />
        </fileset>
        <fileset dir="${dist.dir}/src/contrib/ec2/bin/image"/>
    </chmod>
    <chmod perm="ugo+x" type="file">
        <fileset dir="${dist.dir}/src/c++/pipes/debug"/>
    </chmod>

  </target>

  <!-- ================================================================== -->
  <!-- Make release tarball                                               -->
  <!-- ================================================================== -->
  <target name="tar" depends="package" description="Make release tarball">
    <macro_tar param.destfile="${build.dir}/${final.name}.tar.gz">
      <param.listofitems>
        <tarfileset dir="${build.dir}" mode="664">
          <exclude name="${final.name}/bin/*" />
          <exclude name="${final.name}/contrib/*/bin/*" />
          <exclude name="${final.name}/src/contrib/ec2/bin/*" />
          <exclude name="${final.name}/src/contrib/ec2/bin/image/*" />
          <exclude name="${final.name}/src/native/configure" />
          <include name="${final.name}/**" />
        </tarfileset>
        <tarfileset dir="${build.dir}" mode="755">
          <include name="${final.name}/bin/*" />
          <include name="${final.name}/contrib/*/bin/*" />
          <include name="${final.name}/src/contrib/ec2/bin/*" />
          <include name="${final.name}/src/contrib/ec2/bin/image/*" />
          <include name="${final.name}/src/native/configure" />
        </tarfileset>
      </param.listofitems>
    </macro_tar>
  </target>

  <target name="superjar" depends="bin-package">        
    <jar jarfile="${build.dir}/${final.name}-super.jar">        
        <zipgroupfileset dir="lib" includes="*jar"/>    
        <zipgroupfileset dir="build" includes="*jar"/>  
        <zipgroupfileset dir="build/contrib/corona" includes="*jar"/>   
        <zipgroupfileset dir="build/contrib/highavailability" includes="*jar"/>   
        <zipgroupfileset dir="build/contrib/raid" includes="*jar"/>   
        <zipgroupfileset dir="build/contrib/corona/lib" includes="*jar"/>       
        <zipgroupfileset dir="build/ivy/lib/Hadoop/common/" includes="*jar"/>   
        <zipgroupfileset dir="build/ivy/lib/corona/common/" includes="*jar"/>   
    </jar>      
  </target>     

  <target name="bin-package" depends="compile, jar, examples, tools-jar, jar-test, ant-tasks, package-librecordio"
		description="assembles artifacts for binary target">
    <mkdir dir="${dist.dir}"/>
    <mkdir dir="${dist.dir}/lib"/>
    <mkdir dir="${dist.dir}/contrib"/>
    <mkdir dir="${dist.dir}/bin"/>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false" flatten="true">
      <fileset dir="${common.ivy.lib.dir}"/>
    </copy>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false">
      <fileset dir="lib">
        <exclude name="**/native/**"/>
      </fileset>
    </copy>

  	<exec dir="${dist.dir}" executable="sh" failonerror="true">
	  <env key="BASE_NATIVE_LIB_DIR" value="${lib.dir}/native"/>
	  <env key="BUILD_NATIVE_DIR" value="${build.dir}/native"/>
	  <env key="DIST_LIB_DIR" value="${dist.dir}/lib/native"/>
    <env key="BUNDLE_SNAPPY_LIB" value="${bundle.snappy}"/>
    <env key="SNAPPY_LIB_DIR" value="${snappy.prefix}/lib"/>
	  <arg line="${native.src.dir}/packageNativeHadoop.sh"/>
    <env key="CGROUP_LIB_DIR" value="${cgroup.prefix}/lib"/>
    </exec>

    <subant target="package">
      <!--Pass down the version in case its needed again and the target
      distribution directory so contribs know where to install to.-->
      <property name="version" value="${version}"/>
      <property name="dist.dir" value="${dist.dir}"/>
      <fileset file="${contrib.dir}/build.xml"/>
    </subant>

    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapps}"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset file="${build.dir}/${final.name}-*.jar"/>
    </copy>

    <copy todir="${dist.dir}/bin">
      <fileset dir="bin"/>
    </copy>

    <copy todir="${dist.dir}/conf">
      <fileset dir="${conf.dir}" excludes="**/*.template"/>
    </copy>

    <copy file="ivy.xml" tofile="${dist.dir}/ivy.xml"/>

    <copy todir="${dist.dir}/ivy">
      <fileset dir="ivy"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset dir=".">
        <include name="*.txt" />
      </fileset>
    </copy>

    <copy todir="${dist.dir}/c++" includeEmptyDirs="false">
      <fileset dir="${build.dir}/c++"/>
    </copy>

    <copy todir="${dist.dir}/" file="build.xml"/>

    <chmod perm="ugo+x" type="file" parallel="false">
        <fileset dir="${dist.dir}/bin"/>
    </chmod>
  </target>

  <target name="binary" depends="bin-package" description="Make tarball without source and documentation">
    <copy todir="${build.dir}/${final.name}" includeEmptyDirs="false">
      <fileset dir="${build.dir}/ivy/maven/">
        <include name="generated.pom"/>
      </fileset>
    </copy>
    <macro_tar param.destfile="${build.dir}/${final.name}-bin.tar.gz">
      <param.listofitems>
        <tarfileset dir="${build.dir}" mode="664">
          <exclude name="${final.name}/bin/*" />
          <exclude name="${final.name}/src/**" />
          <exclude name="${final.name}/docs/**" />
          <include name="${final.name}/**" />
        </tarfileset>
        <tarfileset dir="${build.dir}" mode="755">
          <include name="${final.name}/bin/*" />
          <include name="${final.name}/generated.pom"/>
        </tarfileset>
      </param.listofitems>
    </macro_tar>
  </target>

  <!-- ================================================================== -->
  <!-- Perform audit activities for the release                           -->
  <!-- ================================================================== -->
  <target name="releaseaudit" depends="package,ivy-retrieve-releaseaudit" description="Release Audit activities">
    <fail unless="rat.present" message="Failed to load class [${rat.reporting.classname}]."/>
    <java classname="${rat.reporting.classname}" fork="true">
      <classpath refid="releaseaudit-classpath"/>
      <arg value="${build.dir}/${final.name}"/>
    </java>
  </target>

  <!-- ================================================================== -->
  <!-- Clean.  Delete the build files, and their directories              -->
  <!-- ================================================================== -->
  <target name="clean" depends="clean-contrib" description="Clean.  Delete the build files, and their directories">
    <delete dir="${build.dir}"/>
    <delete dir="${docs.src}/build"/>
    <delete file="${jdiff.xml.dir}/hadoop_${version}.xml"/>
    <delete file="${conf.dir}/hdfs-site.xml"/>
    <delete file="${conf.dir}/core-site.xml"/>
    <delete file="${conf.dir}/hadoop-policy.xml"/>
    <delete file="${conf.dir}/capacity-scheduler.xml"/>
    <delete file="${conf.dir}/mapred-site.xml"/>
    <delete file="${conf.dir}/mapred-queue-acls.xml"/>
    <delete file="${conf.dir}/slaves"/>
    <delete file="${conf.dir}/masters"/>
  </target>

  <!-- ================================================================== -->
  <!-- Clean contrib target. For now, must be called explicitly           -->
  <!-- Using subant instead of ant as a workaround for 30569              -->
  <!-- ================================================================== -->
  <target name="clean-contrib">
     <subant target="clean">
        <fileset file="src/contrib/build.xml"/>
     </subant>
  </target>

 <target name="test-c++-libhdfs" depends="compile-c++-libhdfs, compile-core" if="islibhdfs">
    <delete dir="${test.libhdfs.dir}"/>
    <mkdir dir="${test.libhdfs.dir}"/>
    <mkdir dir="${test.libhdfs.dir}/logs"/>
    <mkdir dir="${test.libhdfs.dir}/hdfs/name"/>

    <exec dir="${build.c++.libhdfs}" executable="${make.cmd}" failonerror="true">
        <env key="OS_NAME" value="${os.name}"/>
        <env key="OS_ARCH" value="${os.arch}"/>
        <env key="JVM_ARCH" value="${jvm.arch}"/>
        <env key="LIBHDFS_BUILD_DIR" value="${build.c++.libhdfs}"/>
        <env key="HADOOP_HOME" value="${basedir}"/>
        <env key="HADOOP_CONF_DIR" value="${test.libhdfs.conf.dir}"/>
        <env key="HADOOP_LOG_DIR" value="${test.libhdfs.dir}/logs"/>
        <env key="LIBHDFS_SRC_DIR" value="${c++.libhdfs.src}"/>
        <env key="LIBHDFS_INSTALL_DIR" value="${install.c++}/lib"/>
        <env key="LIB_DIR" value="${common.ivy.lib.dir}"/>
		<arg value="test"/>
    </exec>
  </target>

<!-- ================================================================== -->
<!-- librecordio targets.                                               -->
<!-- ================================================================== -->

  <target name="compile-librecordio" depends="init" if="librecordio" >
     <mkdir dir="${build.librecordio}"/>
     <exec dir="${librecordio.src}" executable="${make.cmd}" failonerror="true">
        <env key="XERCESCROOT" value="${xercescroot}"/>
        <env key="LIBRECORDIO_BUILD_DIR" value="${build.librecordio}"/>
     </exec>
  </target>

  <target name="test-librecordio" depends="compile-librecordio, compile-core" if="librecordio">
    <delete dir="${librecordio.test.dir}"/>
    <mkdir dir="${librecordio.test.dir}"/>
    <exec dir="${librecordio.src}/test" executable="${make.cmd}" failonerror="true">
        <env key="HADOOP_HOME" value="${basedir}"/>
	<env key="XERCESCROOT" value="${xercescroot}"/>
        <env key="LIBRECORDIO_BUILD_DIR" value="${build.librecordio}"/>
        <env key="LIBRECORDIO_TEST_DIR" value="${librecordio.test.dir}"/>
      		<arg value="all"/>
    </exec>
  </target>

  <target name="package-librecordio" depends="compile-librecordio" if="librecordio">
    <mkdir dir="${dist.dir}/librecordio"/>
    <copy todir="${dist.dir}/librecordio">
       <fileset dir="${build.librecordio}" casesensitive="yes" followsymlinks="false">
          <exclude name="**/tests/**"/>
          <exclude name="*.so"/>
          <exclude name="*.o"/>
       </fileset>
    </copy>
    <chmod perm="ugo+x" type="file">
       <fileset dir="${dist.dir}/librecordio"/>
    </chmod>
  </target>

  <target name="create-c++-configure" depends="init" if="compile.c++">
    <exec executable="autoreconf" dir="${c++.utils.src}" searchpath="yes"
          failonerror="yes">
       <arg value="-if"/>
    </exec>
    <exec executable="autoreconf" dir="${c++.pipes.src}" searchpath="yes"
          failonerror="yes">
       <arg value="-if"/>
    </exec>
    <exec executable="autoreconf" dir="${c++.examples.pipes.src}"
          searchpath="yes" failonerror="yes">
       <arg value="-if"/>
    </exec>
    <antcall target="create-c++-configure-libhdfs"/>
  </target>

  <target name="create-c++-configure-libhdfs" depends="check-c++-libhdfs" if="islibhdfs">
    <exec executable="autoreconf" dir="${c++.libhdfs.src}"
          searchpath="yes" failonerror="yes">
       <arg value="-if"/>
    </exec>
  </target>

  <target name="check-c++-makefiles" depends="init" if="compile.c++">
    <condition property="need.c++.utils.makefile">
       <not> <available file="${build.c++.utils}/Makefile"/> </not>
    </condition>
    <condition property="need.c++.pipes.makefile">
       <not> <available file="${build.c++.pipes}/Makefile"/> </not>
    </condition>
    <condition property="need.c++.examples.pipes.makefile">
       <not> <available file="${build.c++.examples.pipes}/Makefile"/> </not>
    </condition>
  </target>

  <target name="check-c++-libhdfs">
    <condition property="islibhdfs">
      <and>
        <isset property="compile.c++"/>
        <isset property="libhdfs"/>
      </and>
    </condition>
  </target>

  <target name="check-c++-makefile-libhdfs" depends="init,check-c++-libhdfs" if="islibhdfs">
    <condition property="need.c++.libhdfs.makefile">
       <not> <available file="${build.c++.libhdfs}/Makefile"/> </not>
    </condition>
  </target>

  <target name="create-c++-libhdfs-makefile" depends="check-c++-makefile-libhdfs"
                                           if="need.c++.libhdfs.makefile">
    <mkdir dir="${build.c++.libhdfs}"/>
    <chmod file="${c++.libhdfs.src}/configure" perm="ugo+x"/>
    <exec executable="${c++.libhdfs.src}/configure" dir="${build.c++.libhdfs}"
          failonerror="yes">
      <env key="ac_cv_func_malloc_0_nonnull" value="yes"/>
      <env key="JVM_ARCH" value="${jvm.arch}"/>
      <arg value="--prefix=${install.c++}"/>
    </exec>
  </target>

  <target name="create-c++-utils-makefile" depends="check-c++-makefiles"
                                           if="need.c++.utils.makefile">
    <mkdir dir="${build.c++.utils}"/>
    <exec executable="${c++.utils.src}/configure" dir="${build.c++.utils}"
          failonerror="yes">
      <arg value="--prefix=${install.c++}"/>
    </exec>
  </target>

  <target name="compile-c++-utils" depends="create-c++-utils-makefile"
                                   if="compile.c++">
    <exec executable="${make.cmd}" dir="${build.c++.utils}" searchpath="yes"
          failonerror="yes">
      <arg  value="install"/>
    </exec>
  </target>

  <target name="create-c++-pipes-makefile" depends="check-c++-makefiles"
                                           if="need.c++.pipes.makefile">
    <mkdir dir="${build.c++.pipes}"/>
    <exec executable="${c++.pipes.src}/configure" dir="${build.c++.pipes}"
          failonerror="yes">
      <arg value="--prefix=${install.c++}"/>
    </exec>
  </target>

  <target name="compile-c++-pipes"
          depends="create-c++-pipes-makefile,compile-c++-utils"
          if="compile.c++">
    <exec executable="${make.cmd}" dir="${build.c++.pipes}" searchpath="yes"
          failonerror="yes">
      <arg value="install"/>
    </exec>
  </target>

  <target name="compile-c++"
          depends="compile-c++-pipes"/>

  <target name="create-c++-examples-pipes-makefile"
          depends="check-c++-makefiles"
          if="need.c++.examples.pipes.makefile">
    <mkdir dir="${build.c++.examples.pipes}"/>
    <exec executable="${c++.examples.pipes.src}/configure"
          dir="${build.c++.examples.pipes}"
          failonerror="yes">
      <arg value="--prefix=${install.c++.examples}"/>
      <arg value="--with-hadoop-utils=${install.c++}"/>
      <arg value="--with-hadoop-pipes=${install.c++}"/>
    </exec>
  </target>

  <target name="compile-c++-examples-pipes"
          depends="create-c++-examples-pipes-makefile,compile-c++-pipes"
          if="compile.c++">
    <exec executable="${make.cmd}" dir="${build.c++.examples.pipes}" searchpath="yes"
          failonerror="yes">
      <arg  value="install"/>
    </exec>
  </target>

  <target name="compile-c++-examples"
          depends="compile-c++-examples-pipes"/>

  <target name="compile-c++-libhdfs" depends="create-c++-libhdfs-makefile" if="islibhdfs">
    <exec executable="${make.cmd}" dir="${build.c++.libhdfs}" searchpath="yes"
          failonerror="yes">
      <env key="ac_cv_func_malloc_0_nonnull" value="yes"/>
      <env key="JVM_ARCH" value="${jvm.arch}"/>
      <arg value="install"/>
    </exec>
  </target>



  <target name="compile-ant-tasks" depends="compile-core">
    <javac
        includeantruntime="true"
        encoding="${build.encoding}"
        srcdir="${anttasks.dir}"
        includes="org/apache/hadoop/ant/**/*.java"
        destdir="${build.anttasks}"
        debug="${javac.debug}"
        optimize="${javac.optimize}"
        target="${javac.version}"
        source="${javac.version}"
        deprecation="${javac.deprecation}">
        <compilerarg line="${javac.args}"/>
        <classpath refid="classpath"/>
    </javac>
  </target>

  <target name="ant-tasks" depends="jar, compile-ant-tasks">
    <copy file="${anttasks.dir}/org/apache/hadoop/ant/antlib.xml"
          todir="${build.anttasks}/org/apache/hadoop/ant"/>
    <jar destfile="${build.dir}/${final.name}-ant.jar">
      <fileset dir="${build.anttasks}"/>
    </jar>
  </target>



 <target name="clover" depends="clover.setup, clover.info" description="Instrument the Unit tests using Clover.  To use, specify -Dclover.home=&lt;base of clover installation&gt; -Drun.clover=true on the command line."/>

<target name="clover.setup" if="clover.enabled">
   <taskdef resource="cloverlib.xml" classpath="${clover.jar}"/>
   <mkdir dir="${clover.db.dir}"/>
   <clover-setup initString="${clover.db.dir}/hadoop_coverage.db">
     <fileset dir="src" includes="core/**/* tools/**/* hdfs/**/* mapred/**/*"/>
   </clover-setup>
</target>

<target name="clover.info" unless="clover.present">
  <echo>
     Clover not found. Code coverage reports disabled.
  </echo>
</target>

<target name="clover.check">
  <fail unless="clover.present">
  ##################################################################
   Clover not found.
   Please specify -Dclover.home=&lt;base of clover installation&gt;
   on the command line.
  ##################################################################
  </fail>
</target>

<target name="generate-clover-reports" depends="clover.check, clover">
  <mkdir dir="${clover.report.dir}"/>
  <clover-report>
     <current outfile="${clover.report.dir}" title="${final.name}">
     <format type="html"/>
     </current>
  </clover-report>
  <clover-report>
     <current outfile="${clover.report.dir}/clover.xml" title="${final.name}">
     <format type="xml"/>
     </current>
  </clover-report>
</target>

<target name="findbugs.check" depends="check-for-findbugs" unless="findbugs.present">
  <fail message="'findbugs.home' is not defined. Please pass -Dfindbugs.home=&lt;base of Findbugs installation&gt; to Ant on the command-line." />
</target>

<target name="patch.check" unless="patch.file">
  <fail message="'patch.file' is not defined. Please pass -Dpatch.file=&lt;location of patch file&gt; to Ant on the command-line." />
</target>

<target name="test-patch" depends="patch.check,findbugs.check,forrest.check">
  <exec executable="bash" failonerror="true">
    <arg value="${basedir}/src/test/bin/test-patch.sh"/>
    <arg value="DEVELOPER"/>
    <arg value="${patch.file}"/>
    <arg value="${scratch.dir}"/>
    <arg value="${svn.cmd}"/>
    <arg value="${grep.cmd}"/>
    <arg value="${patch.cmd}"/>
    <arg value="${findbugs.home}"/>
    <arg value="${forrest.home}"/>
    <arg value="${basedir}"/>
    <arg value="${java5.home}"/>
  </exec>
</target>

<target name="hudson-test-patch" depends="findbugs.check,forrest.check">
  <exec executable="bash" failonerror="true">
    <arg value="${basedir}/src/test/bin/test-patch.sh"/>
    <arg value="HUDSON"/>
    <arg value="${scratch.dir}"/>
    <arg value="${support.dir}"/>
    <arg value="${ps.cmd}"/>
    <arg value="${wget.cmd}"/>
    <arg value="${jiracli.cmd}"/>
    <arg value="${svn.cmd}"/>
    <arg value="${grep.cmd}"/>
    <arg value="${patch.cmd}"/>
    <arg value="${findbugs.home}"/>
    <arg value="${forrest.home}"/>
    <arg value="${eclipse.home}"/>
    <arg value="${python.home}"/>
    <arg value="${basedir}"/>
    <arg value="${trigger.url}"/>
    <arg value="${jira.passwd}"/>
    <arg value="${java5.home}"/>
  </exec>
</target>

  <target name="eclipse-files" depends="init"
          description="Generate files for Eclipse">
    <pathconvert property="eclipse.project">
      <path path="${basedir}"/>
      <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
    </pathconvert>
    <copy todir="." overwrite="true">
      <fileset dir=".eclipse.templates">
      	<exclude name="**/README.txt"/>
      </fileset>
      <filterset>
        <filter token="PROJECT" value="${eclipse.project}"/>
      </filterset>
    </copy>
  </target>

  <target name="ivy-init-dirs">
    <mkdir dir="${build.ivy.dir}" />
    <mkdir dir="${build.ivy.lib.dir}" />
    <mkdir dir="${build.ivy.report.dir}" />
    <mkdir dir="${build.ivy.maven.dir}" />
  </target>

  <target name="ivy-probe-antlib" >
    <condition property="ivy.found">
      <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
    </condition>
  </target>

  <target name="ivy-download" description="To download ivy" unless="offline">
    <retry retrycount="10">
      <get src="${ivy_repo_url}" dest="${ivy.jar}" usetimestamp="true"/>
    </retry>
  </target>

  <!--
  To avoid Ivy leaking things across big projects, always load Ivy in the same classloader.
  Also note how we skip loading Ivy if it is already there, just to make sure all is well.
  -->
  <target name="ivy-init-antlib" depends="ivy-download,ivy-init-dirs,ivy-probe-antlib" unless="ivy.found">
    <typedef uri="antlib:org.apache.ivy.ant" onerror="fail"
      loaderRef="ivyLoader">
      <classpath>
        <pathelement location="${ivy.jar}"/>
      </classpath>
    </typedef>
    <fail >
      <condition >
        <not>
          <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
        </not>
      </condition>
      You need Apache Ivy 2.0 or later from http://ant.apache.org/
      It could not be loaded from ${ivy_repo_url}
    </fail>
  </target>


  <target name="ivy-init" depends="ivy-init-antlib" >

    <!--Configure Ivy by reading in the settings file
        If anyone has already read in a settings file into this settings ID, it gets priority
    -->
    <ivy:configure settingsid="${ant.project.name}.ivy.settings" file="${ivysettings.xml}" override='false'/>
  </target>

  <target name="ivy-resolve" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings"/>
  </target>

  <target name="ivy-resolve-javadoc" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="javadoc"/>
  </target>

  <target name="ivy-resolve-releaseaudit" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="releaseaudit"/>
  </target>

  <target name="ivy-resolve-test" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="test" />
  </target>

  <target name="ivy-resolve-common" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="common" />
  </target>

  <target name="ivy-resolve-jdiff" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="jdiff" />
  </target>

  <target name="ivy-resolve-checkstyle" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="checkstyle"/>
  </target>

  <target name="ivy-retrieve" depends="ivy-resolve"
    description="Retrieve Ivy-managed artifacts">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
  </target>

  <target name="ivy-retrieve-checkstyle" depends="ivy-resolve-checkstyle"
    description="Retrieve Ivy-managed artifacts for the checkstyle configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="checkstyle-classpath" conf="checkstyle"/>
  </target>

  <target name="ivy-retrieve-jdiff" depends="ivy-resolve-jdiff"
    description="Retrieve Ivy-managed artifacts for the javadoc configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="jdiff-classpath" conf="jdiff"/>
  </target>

  <target name="ivy-retrieve-javadoc" depends="ivy-resolve-javadoc"
    description="Retrieve Ivy-managed artifacts for the javadoc configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="javadoc-classpath" conf="javadoc"/>
  </target>

  <target name="ivy-retrieve-test" depends="ivy-resolve-test"
    description="Retrieve Ivy-managed artifacts for the test configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="test.classpath" conf="test"/>
  </target>

  <target name="ivy-retrieve-common" depends="ivy-resolve-common"
    description="Retrieve Ivy-managed artifacts for the compile configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="ivy-common.classpath" conf="common"/>
  </target>

  <target name="ivy-retrieve-releaseaudit" depends="ivy-resolve-releaseaudit"
    description="Retrieve Ivy-managed artifacts for the compile configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}" />
    <ivy:cachepath pathid="releaseaudit-classpath" conf="releaseaudit"/>
    <available classname="${rat.reporting.classname}"
      classpathref="releaseaudit-classpath" property="rat.present" value="true"/>
  </target>

  <target name="ivy-report" depends="ivy-resolve-releaseaudit"
    description="Generate">
    <ivy:report todir="${build.ivy.report.dir}" settingsRef="${ant.project.name}.ivy.settings"/>
    <echo>
      Reports generated:${build.ivy.report.dir}
    </echo>
  </target>

  <target name="assert-hadoop-jar-exists" depends="ivy-init">
    <fail>
      <condition >
        <not>
          <available file="${hadoop.jar}" />
        </not>
      </condition>
      Not found: ${hadoop.jar}
      Please run the target "jar" in the main build file
    </fail>

  </target>

  <target name="ready-to-publish" depends="jar,assert-hadoop-jar-exists,ivy-resolve"/>

  <target name="ivy-publish-local" depends="ready-to-publish,ivy-resolve">
    <ivy:publish
      settingsRef="${ant.project.name}.ivy.settings"
      resolver="local"
      pubrevision="${version}"
      overwrite="true"
      artifactspattern="${build.dir}/${ivy.publish.pattern}" />
  </target>


  <!-- this is here for curiosity, to see how well the makepom task works
  Answer: it depends whether you want transitive dependencies excluded or not
  -->
  <target name="makepom" depends="ivy-resolve">
    <ivy:makepom settingsRef="${ant.project.name}.ivy.settings"
      ivyfile="ivy.xml"
      pomfile="${build.ivy.maven.dir}/generated.pom">
      <ivy:mapping conf="default" scope="default"/>
      <ivy:mapping conf="master" scope="master"/>
      <ivy:mapping conf="runtime" scope="runtime"/>
    </ivy:makepom>
  </target>


  <target name="copy-jar-to-maven" depends="ready-to-publish">
    <copy file="${hadoop.jar}"
      tofile="${build.ivy.maven.jar}"/>
    <checksum file="${build.ivy.maven.jar}" algorithm="md5"/>
  </target>

  <target name="copypom" depends="ivy-init-dirs">

   <presetdef name="expandingcopy" >
    <copy overwrite="true">
      <filterchain>
        <expandproperties/>
      </filterchain>
    </copy>
   </presetdef>

   <expandingcopy file="ivy/hadoop-core.pom"
      tofile="${build.ivy.maven.pom}"/>
   <checksum file="${build.ivy.maven.pom}" algorithm="md5"/>
  </target>

  <target name="maven-artifacts" depends="copy-jar-to-maven,copypom" />

  <target name="published" depends="ivy-publish-local,maven-artifacts">

  </target>

  <!-- taskcontroller targets -->
  <target name="init-task-controller-build">
    <mkdir dir="${build.c++.task-controller}" />
    <copy todir="${build.c++.task-controller}">
      <fileset dir="${c++.task-controller.src}" includes="*.c">
      </fileset>
      <fileset dir="${c++.task-controller.src}" includes="*.h">
      </fileset>
    </copy>
    <chmod file="${c++.task-controller.src}/configure" perm="ugo+x"/>
    <condition property="task-controller.conf.dir.passed">
      <not>
        <equals arg1="${hadoop.conf.dir}" arg2="$${hadoop.conf.dir}"/>
      </not>
    </condition>
  </target>
  <target name="configure-task-controller" depends="init,
          init-task-controller-build,
          task-controller-configuration-with-confdir,
          task-controller-configuration-with-no-confdir">
  </target>
  <target name="task-controller-configuration-with-confdir"
          if="task-controller.conf.dir.passed" >
    <exec executable="${c++.task-controller.src}/configure"
          dir="${build.c++.task-controller}" failonerror="yes">
      <arg value="--prefix=${task-controller.install.dir}" />
      <arg value="--with-confdir=${hadoop.conf.dir}" />
    </exec>
  </target>
  <target name="task-controller-configuration-with-no-confdir"
          unless="task-controller.conf.dir.passed">
    <exec executable="${c++.task-controller.src}/configure"
          dir="${build.c++.task-controller}" failonerror="yes">
      <arg value="--prefix=${task-controller.install.dir}" />
    </exec>
  </target>
  <!--
    * Create the installation directory.
    * Do a make install.
   -->
  <target name="task-controller" depends="configure-task-controller">
    <mkdir dir="${task-controller.install.dir}" />
    <exec executable="${make.cmd}" dir="${build.c++.task-controller}"
        searchpath="yes" failonerror="yes">
      <arg value="install" />
    </exec>
  </target>
  <!-- end of task-controller target -->

  <target name="print-version">
    <echo message="${version}" />
  </target>
</project>

<?xml version="1.0" ?>
<project default="main" basedir=".">
    <property name="Name" value="gridmix"/>
    <property name="version" value="0.1"/>
    <property name="final.name" value="${name}-${version}"/>
    <property name="year" value="2008"/>	
	<property name="hadoop.dir" value="${basedir}/../../../"/>
    <property name="lib.dir" value="${hadoop.dir}/lib"/>
    <property name="src.dir" value="${basedir}/src"/>
    <property name="conf.dir" value="${basedir}/conf"/>
    <property name="docs.dir" value="${basedir}/docs"/>
    <property name="build.dir" value="${basedir}/build"/>
    <property name="dist.dir" value="${basedir}/dist"/>
    <property name="build.classes" value="${build.dir}/classes"/>
	
    <target name="init">
        <mkdir dir="${build.dir}"/>
        <mkdir dir="${dist.dir}"/>
    </target>

    <target name="main" depends="init, compile, compress" description="Main target">
        <echo>
            Building the .jar files.
        </echo>
    </target>
  
    <target name="compile" depends="init" description="Compilation target">
        <javac srcdir="src/java/" destdir="${build.dir}">
        	<classpath refid="classpath" />
        </javac>
    </target>
	

	 <target name="compress" depends="compile" description="Compression target">
  	      <jar jarfile="${build.dir}/gridmix.jar" basedir="${build.dir}" includes="**/*.class" />
                   

        <copy todir="." includeEmptyDirs="false">
            <fileset dir="${build.dir}">
	        <exclude name="**" />
	        <include name="**/*.jar" />
            </fileset>
        </copy>
    </target>

  
    <!-- ================================================================== -->
    <!-- Clean.  Delete the build files, and their directories              -->
    <!-- ================================================================== -->
    <target name="clean" description="Clean.  Delete the build files, and their directories">
      <delete dir="${build.dir}"/>
      <delete dir="${dist.dir}"/>
    </target>

    <!-- the normal classpath -->
    <path id="classpath">
	    <pathelement location="${build.classes}"/>
	    <fileset dir="${lib.dir}">
	       <include name="*.jar" />
	       <exclude name="**/excluded/" />
	    </fileset>
	    <fileset dir="${hadoop.dir}">
	       <include name="**.jar" />
           <include name="contrib/streaming/*.jar" />
	    </fileset>
    </path>
</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="benchmark" default="jar">
  <import file="../build-contrib.xml"/>

  <property name="version" value="0.20.1"/>



  <target name="jar" depends="compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"
    >
      <manifest>
        <attribute name="Main-Class" value="org.apache.hadoop.hdfs.AllTestDriver"/>
      </manifest>
    </jar>
  </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="hadoopcontrib" default="compile" basedir=".">

  <!-- In case one of the contrib subdirectories -->
  <!-- fails the build or test targets and you cannot fix it: -->
  <!-- Then add to fileset: excludes="badcontrib/build.xml" -->

  <!-- ====================================================== -->
  <!-- Compile contribs.                                      -->
  <!-- ====================================================== -->
  <target name="jar-source">
    <subant target="jar-source">
      <fileset dir="." includes="highavailability/build.xml"/>
      <fileset dir="." includes="storageservice/build.xml"/>
      <fileset dir="." includes="raid/build.xml"/>
      <fileset dir="." includes="corona/build.xml"/>
      <fileset dir="." includes="seekablecompression/build.xml"/>
    </subant>
  </target>

  <target name="compile">
    <subant target="compile">
      <fileset dir="." includes="highavailability/build.xml"/>
      <fileset dir="." includes="storageservice/build.xml"/>
      <fileset dir="." includes="raid/build.xml"/>
      <fileset dir="." includes="benchmark/build.xml"/>
      <fileset dir="." includes="streaming/build.xml"/>
      <fileset dir="." includes="fairscheduler/build.xml"/>
      <fileset dir="." includes="gridmix/build.xml"/>
      <fileset dir="." includes="corona/build.xml"/>
      <fileset dir="." includes="seekablecompression/build.xml"/>
      <fileset dir="." includes="fsshellservice/build.xml" />
      <fileset dir="." includes="namespace-notifier/build.xml" />
      <fileset dir="." includes="bittorrent/build.xml" />
    </subant>
  </target>

  <!-- ====================================================== -->
  <!-- Package contrib jars.                                  -->
  <!-- ====================================================== -->
  <target name="package">
    <subant target="package">
      <fileset dir="." includes="*/build.xml"> 
        <exclude name="snapshot/build.xml"/>
      </fileset>
    </subant>
  </target>

  <!-- ====================================================== -->
  <!-- Test all the contribs.                               -->
  <!-- ====================================================== -->
  <target name="test">
    <subant target="test" failonerror="false">
      <fileset dir="." includes="streaming/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="fairscheduler/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="gridmix/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="storageservice/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="raid/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="corona/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="seekablecompression/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="highavailability/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="namespace-notifier/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="fsshellservice/build.xml"/>
    </subant>
  </target>

  <!-- ====================================================== -->
  <!-- Test the hdfs contribs.                                -->
  <!-- ====================================================== -->
  <target name="test-hdfs">
    <subant target="test" failonerror="false">
      <fileset dir="." includes="storageservice/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="raid/build.xml"/>
    </subant>
    <subant target="test" failonerror="false">
      <fileset dir="." includes="highavailability/build.xml"/>
    </subant>
  </target>

  <!-- ====================================================== -->
  <!-- Compile all the contrib tests.                         -->
  <!-- ====================================================== -->
  <target name="compile-test">
    <subant target="compile-test">
      <fileset dir="." includes="streaming/build.xml"/>
      <fileset dir="." includes="fairscheduler/build.xml"/>
      <fileset dir="." includes="capacity-scheduler/build.xml"/>
      <fileset dir="." includes="gridmix/build.xml"/>
      <fileset dir="." includes="raid/build.xml"/>
      <fileset dir="." includes="corona/build.xml"/>
      <fileset dir="." includes="highavailability/build.xml"/>
      <fileset dir="." includes="namespace-notifier/build.xml"/>
      <fileset dir="." includes="storageservice/build.xml"/>
      <fileset dir="." includes="seekablecompression/build.xml"/>
    </subant>
  </target>


  <!-- ====================================================== -->
  <!-- Clean all the contribs.                              -->
  <!-- ====================================================== -->
  <target name="clean">
    <subant target="clean">
      <fileset dir="." includes="*/build.xml"/>
    </subant>
  </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="capacity-scheduler" default="jar">

  <import file="../build-contrib.xml"/>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="corona" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

  <property name="gen.java.dir" value="${root}/src/gen-java"/>
  <property name="build.webapp" value="${build.dir}/webapps"/>
  <property name="src.webapp.jt" value="${basedir}/src/webapp/jt"/>
  <property name="src.webapp.cm" value="${basedir}/src/webapp/cm"/>
  <property name="src.webapp.proxyjt" value="${basedir}/src/webapp/proxyjt"/>
  <property name="build.src" value="${build.dir}/src" />
  <property name="test.src.dir" value="${basedir}/src/test"/>
  <property name="test.build.dir" value="${build.dir}/test"/>
  <property name="src.dir" value="${basedir}/src/java"/>

  <!-- Run this if you change the thrift interface file -->
  <target name="thriftif" depends="init">
    <echo>Executing thrift (needs to be in PATH) to build corona APIs</echo>
    <exec executable="thrift" dir="${root}">
     <arg line="--gen java -o ${root}/src interface/ClusterManager.thrift" />
    </exec>
  </target>

  <target name="compile-thrift" depends="init, ivy-retrieve-common">
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${gen.java.dir}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
    </javac>
  </target>

  <target name="checkstyle" depends="ivy-retrieve-checkstyle,check-for-checkstyle" if="checkstyle.present" description="Run optional third-party tool targets">
    <taskdef resource="checkstyletask.properties">
      <classpath refid="checkstyle-classpath"/>
    </taskdef>
    
    <mkdir dir="${test.build.dir}"/>
    
    <checkstyle config="${test.src.dir}/checkstyle.xml"
  		failOnViolation="false">
      <property key="checkstyle.header.file" file="${basedir}/src/test/license-header.txt"/>
      <fileset dir="${src.dir}" includes="**/*.java" excludes="**/generated/**"/>
      <formatter type="xml" toFile="${test.build.dir}/checkstyle-errors.xml"/>
    </checkstyle>
    
    <xslt style="${test.src.dir}/checkstyle-noframes-sorted.xsl"
          in="${test.build.dir}/checkstyle-errors.xml"
          out="${test.build.dir}/checkstyle-errors.html"/>
  </target>
  
  <target name="check-for-checkstyle">
    <available property="checkstyle.present" resource="checkstyletask.properties">
      <classpath refid="checkstyle-classpath"/>
    </available>
  </target>
  
  <!-- Override jar target to specify thrift dependency -->
  <target name="compile" depends="init, ivy-retrieve-common, compile-thrift, checkstyle, copy.libs" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
       <classpath refid="test.classpath"/>
    </taskdef>
    <mkdir dir="${build.webapp}/jt/WEB-INF"/>  
    <copy file="${src.webapp.jt}/index.html" todir="${build.webapp}/jt"/>
    <jsp-compile
     uriroot="${src.webapp.jt}"
     outputdir="${build.src}"
     package="org.apache.hadoop.mapred"
     webxml="${build.webapp}/jt/WEB-INF/web.xml">
    </jsp-compile>
    <mkdir dir="${build.webapp}/cm/WEB-INF"/>  
    <copy file="${src.webapp.cm}/index.html" todir="${build.webapp}/cm"/>
    <jsp-compile
     uriroot="${src.webapp.cm}"
     outputdir="${build.src}"
     package="org.apache.hadoop.corona"
     webxml="${build.webapp}/cm/WEB-INF/web.xml">
    </jsp-compile>
    <mkdir dir="${build.webapp}/proxyjt/WEB-INF"/>  
    <copy file="${src.webapp.proxyjt}/index.html" todir="${build.webapp}/proxyjt"/>
    <jsp-compile
     uriroot="${src.webapp.proxyjt}"
     outputdir="${build.src}"
     package="org.apache.hadoop.corona"
     webxml="${build.webapp}/proxyjt/WEB-INF/web.xml">
    </jsp-compile>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.dir};${build.src}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
    </javac>
    <copy file="${src.dir}/error.xml" todir="${build.classes}"/>
  </target>

  <target name="copy.libs">
    <mkdir dir="${build.dir}/lib"/>
    <copy todir="${build.dir}/lib">
      <!-- Copies the libthrift jar and the thrift API jar -->
      <fileset dir="${src.dir}/../../lib"/>
      <!-- Copies the thrift definition. Useful as a lib reference -->
      <fileset dir="${src.dir}/../../interface"/>
    </copy>
  </target>

  <target name="jar" depends="compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}">
    </jar>

  </target>

  <target name="package" depends="jar, jar-examples" unless="skip.contrib">
    <mkdir dir="${dist.dir}/contrib/${name}"/>
    <copy todir="${dist.dir}/contrib/${name}" includeEmptyDirs="false" flatten="true">
      <fileset dir="${build.dir}">
        <include name="hadoop-${version}-${name}.jar" />
      </fileset>
    </copy>

    <copy todir="${dist.dir}/contrib/${name}">
      <fileset dir="${build.dir}">
        <include name="**/lib/"/>
      </fileset>
    </copy>

    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapp}"/>
    </copy>

  </target>

  <target name="ivy-retrieve-checkstyle" depends="ivy-resolve-checkstyle"
    description="Retrieve Ivy-managed artifacts for the checkstyle configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="checkstyle-classpath" conf="checkstyle"/>
  </target>

  <target name="ivy-resolve-checkstyle" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="checkstyle"/>
  </target>


</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="datajoin" default="jar">

  <import file="../build-contrib.xml"/>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile">
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"      
    >
  	<manifest>
	    <attribute name="Main-Class" value="org.apache.hadoop.contrib.utils.join.DataJoinJob"/>
	</manifest>
    </jar>
  </target>

  <target name="jar-examples" depends="jar">
   <antcall target="hadoopbuildcontrib.jar-examples">
   </antcall>
  </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="dynamicclouds" default="jar">

  <path id="dynamicclouds.common-classpath" />
  
  <import file="../build-contrib.xml"/>
  
  <property name="build.webapp" value="${build.dir}/webapp"/>
  <property name="src.webapp" value="${root}/src/webapps" />
  <property name="build.src" value="${build.dir}/src" />
  
  <target name="compile" depends="init, ivy-retrieve-common" unless="skip.contrib">
    <echo message="compiling jsp"/>
    <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
       <classpath refid="test.classpath"/>
    </taskdef>
    <echo message="${build.webapp}" />
    <mkdir dir="${build.webapp}/cb/WEB-INF"/>  
    <jsp-compile
     uriroot="${src.webapp}/cb"
     outputdir="${build.src}"
     package="org.apache.hadoop.mapred"
     webxml="${build.webapp}/cb/WEB-INF/web.xml">
    </jsp-compile>

    <echo message="contrib: ${name}"/>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.dir};${build.src}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
    </javac>

  </target>
  
	<property name="jarfile" value="${root}/${name}.jar"/>
  <target name="jar" depends="compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <jar jarfile="${jarfile}" basedir="${build.classes}">
      <manifest>
        <attribute name="Main-Class" value="org.apache.hadoop.mapred.ClustersBalancer"/>
      </manifest>
      <zipfileset dir="${build.webapp}" prefix="webapp"/>
    </jar>
  </target>
  <target name="clean" >
    <delete dir="${build.dir}" />
    <delete dir="${build.webapp}" />
    <delete file="${jarfile}" />
  </target>
</project>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project default="jar" name="eclipse-plugin">

  <import file="../build-contrib.xml"/>

  <path id="eclipse-sdk-jars">
    <fileset dir="${eclipse.home}/plugins/">
      <include name="org.eclipse.ui*.jar"/>
      <include name="org.eclipse.jdt*.jar"/>
      <include name="org.eclipse.core*.jar"/>
      <include name="org.eclipse.equinox*.jar"/>
      <include name="org.eclipse.debug*.jar"/>
      <include name="org.eclipse.osgi*.jar"/>
      <include name="org.eclipse.swt*.jar"/>
      <include name="org.eclipse.jface*.jar"/>

      <include name="org.eclipse.team.cvs.ssh2*.jar"/>
      <include name="com.jcraft.jsch*.jar"/>
    </fileset> 
  </path>

  <!-- Override classpath to include Eclipse SDK jars -->
  <path id="classpath">
    <pathelement location="${build.classes}"/>
    <pathelement location="${hadoop.root}/build/classes"/>
    <path refid="eclipse-sdk-jars"/>
  </path>

  <!-- Skip building if eclipse.home is unset. -->
  <target name="check-contrib" unless="eclipse.home">
    <property name="skip.contrib" value="yes"/>
    <echo message="eclipse.home unset: skipping eclipse plugin"/>
  </target>

 <target name="compile" depends="init, ivy-retrieve-common" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <javac
     encoding="${build.encoding}"
     srcdir="${src.dir}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="classpath"/>
    </javac>
  </target>

  <!-- Override jar target to specify manifest -->
  <target name="jar" depends="compile" unless="skip.contrib">
    <mkdir dir="${build.dir}/lib"/>
    <copy file="${hadoop.root}/build/hadoop-${version}-core.jar" tofile="${build.dir}/lib/hadoop-core.jar" verbose="true"/>
    <copy file="${hadoop.root}/build/ivy/lib/Hadoop/common/commons-cli-${commons-cli.version}.jar"  todir="${build.dir}/lib" verbose="true"/>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      manifest="${root}/META-INF/MANIFEST.MF">
      <fileset dir="${build.dir}" includes="classes/ lib/"/>
      <fileset dir="${root}" includes="resources/ plugin.xml"/>
    </jar>
  </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="failmon" default="compile">

  <import file="../build-contrib.xml"/>

  <property name="jarfile" value="${build.dir}/${name}.jar"/>

  <target name="jar" depends="compile" unless="skip.contrib">
    <!-- Make sure that the hadoop jar has been created -->
<!-- This works, but causes findbugs to fail
    <subant antfile="build.xml" target="jar">
      <fileset dir="../../.." includes="build.xml"/>
    </subant>
-->
    <!-- Copy the required files so that the jar can run independently
	 of Hadoop source code -->
    
  <!-- create the list of files to add to the classpath -->
  <fileset dir="${hadoop.root}/lib" id="class.path">
    <include name="**/*.jar" />
    <exclude name="**/excluded/" />
  </fileset>
  
  <pathconvert pathsep=" " property="failmon-class-path" refid="class.path">
    <map from="${basedir}/" to=""/>
  </pathconvert>

    <echo message="contrib: ${name}"/>
    <jar jarfile="${jarfile}" basedir="${build.classes}">
      <manifest>
        <attribute name="Main-Class" value="org.apache.hadoop.contrib.failmon.RunOnce"/>
	<attribute name="Class-Path" value="${failmon-class-path}"/> 
      </manifest>
    </jar>

  </target>

  
  <!-- Override test target to copy sample data -->
  <target name="test" depends="compile-test, compile, compile-examples" if="test.available">
    <echo message="contrib: ${name}"/>
    <delete dir="${hadoop.log.dir}"/>
    <mkdir dir="${hadoop.log.dir}"/>
    <delete dir="${build.test}/sample"/>
    <mkdir dir="${build.test}/sample"/>
    <copy todir="${build.test}/sample">
      <fileset dir="${root}/sample"/>
    </copy>
    <junit
      printsummary="yes" showoutput="${test.output}" 
      haltonfailure="no" fork="yes" maxmemory="256m"
      errorProperty="tests.failed" failureProperty="tests.failed"
      timeout="${test.timeout}">
      
      <sysproperty key="test.build.data" value="${build.test}/data"/>
      <sysproperty key="build.test" value="${build.test}"/>
      <sysproperty key="contrib.name" value="${name}"/>
      
      <!-- requires fork=yes for: 
        relative File paths to use the specified user.dir 
        classpath to use build/contrib/*.jar
      -->
      <sysproperty key="user.dir" value="${build.test}/data"/>
      
      <sysproperty key="fs.default.name" value="${fs.default.name}"/>
      <sysproperty key="hadoop.test.localoutputfile" value="${hadoop.test.localoutputfile}"/>
      <sysproperty key="hadoop.log.dir" value="${hadoop.log.dir}"/>
      <classpath refid="test.classpath"/>
      <formatter type="${test.junit.output.format}" />
      <batchtest todir="${build.test}" unless="testcase">
        <fileset dir="${src.test}"
                 includes="**/Test*.java" excludes="**/${test.exclude}.java" />
      </batchtest>
      <batchtest todir="${build.test}" if="testcase">
        <fileset dir="${src.test}" includes="**/${testcase}.java"/>
      </batchtest>
    </junit>
    <fail if="tests.failed">Tests failed!</fail>

  </target>
  
  <target name="tar" depends="jar">

    <copy todir=".">
      <fileset dir="${hadoop.root}/build/contrib/failmon/"
	       includes="failmon.jar"/>
    </copy>
    
    <tar tarfile="${name}.tar" 
	 basedir=".." 
	 includes="${name}/**"
	 excludes="${name}/${name}.tar.gz, ${name}/src/**, ${name}/logs/**, ${name}/build.xml*"/>
    <gzip zipfile="${name}.tar.gz" src="${name}.tar"/>
    <delete file="${name}.tar"/>
    <delete file="${name}.jar"/>

    <move file="${name}.tar.gz" todir="${build.dir}"/>
    <echo message= "${hadoop.root}/build/contrib/failmon/${name}.jar"/>
    
  </target>
  
</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="fairscheduler" default="jar">

  <!-- ====================================================== -->
  <!-- Copy static/jsp files for this project to webapps root -->
  <!-- ====================================================== -->
  <target name="init-contrib" if="webapps.available">
    <copy todir="${build.webapps}">
        <fileset dir="${src.webapps}">
          <exclude name="**/*.jsp"/>
          <exclude name="**/*.jspx"/>
        </fileset>
      </copy>
  </target>

  <import file="../build-contrib.xml"/>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="fsshellservice" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

  <property name="src.dir" value="${basedir}/src/java"/>

  <target name="check-thrift-home">
    <echo message="Project: ${ant.project.name}"/>
    <condition property="thrift.home.defined">
      <or>
        <not>
          <isset property="thrift.home"/>
        </not>
        <equals arg1="${thrift.home}" arg2="$${thrift.home}" trim="true"/>
      </or>
    </condition>
  </target>

  <target name="thriftif" depends="check-thrift-home">
    <echo message="${ant.project.name}"/>
    <fail unless="thrift.home">You must set the 'thrift.home' property!</fail>
    <echo>Executing ${thrift.home}/bin/thrift on ${ant.project.name}/if/fsshellservice.thrift</echo>
    <exec executable="${thrift.home}/bin/thrift"  failonerror="true" dir=".">
      <arg line=" --gen java -o ${basedir} if/fsshellservice.thrift " />
    </exec>
  </target>

  <target name="compile" depends="init, ivy-retrieve-common" unless="skip.contrib">
    <echo message="contrib: ${name}" />
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.dir}:${root}/gen-java"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
      <classpath refid="contrib-classpath"/>
      <classpath path="${src.dir}/lib/libthrift-0.7.0.jar"/>
    </javac>
    <copy todir="${build.classes}">
       <fileset dir="${root}/conf">
         <include name="fsshellservice-default.xml" />
       </fileset>
    </copy>
  </target>

  <target name="package" depends="jar, jar-examples" unless="skip.contrib">
   <mkdir dir="${dist.dir}/contrib/${name}"/>
   <mkdir dir="${dist.dir}/contrib/${name}/conf"/>
   <copy todir="${dist.dir}/contrib/${name}">
    <fileset dir="${build.dir}">
       <include name="hadoop-${version}-${name}.jar" />
     </fileset>
   </copy>
   <copy todir="${dist.dir}/contrib/${name}/conf">
     <fileset dir="${root}/conf">
       <include name="fsshellservice-site.xml" />
     </fileset>
   </copy>
  </target>

</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="fuse-dfs" default="compile">

  <import file="../build-contrib.xml"/>

  <target name="check-libhdfs-fuse">
    <condition property="libhdfs-fuse">
      <and>
        <isset property="fusedfs"/>
        <isset property="libhdfs"/>
      </and>
    </condition>
  </target>


  <target name="check-libhdfs-exists" if="fusedfs">
  <property name="libhdfs.lib" value="${hadoop.root}/build/libhdfs/libhdfs.so"/>
        <available file="${libhdfs.lib}" property="libhdfs-exists"/>
    <fail message="libhdfs.so does not exist: ${libhdfs.lib}. Please check flags -Dlibhdfs=1 -Dfusedfs=1 are set or first try ant compile-libhdfs -Dlibhdfs=1">
         <condition>
            <not><isset property="libhdfs-exists"/></not>
          </condition>
   </fail>
   </target>

  <!-- override compile target !-->
  <target name="compile" depends="check-libhdfs-fuse,check-libhdfs-exists" if="libhdfs-fuse">
    <echo message="contrib: ${name}"/>

    <condition property="perms" value="1" else="0">
    <not>
      <isset property="libhdfs.noperms"/>
    </not>
    </condition>

    <exec executable="/bin/sh" failonerror="true">
      <arg value="${root}/bootstrap.sh"/>
    </exec>
    <exec executable="make" failonerror="true">
      <env key="OS_NAME" value="${os.name}"/>
      <env key="OS_ARCH" value="${os.arch}"/>
      <env key="HADOOP_HOME" value="${hadoop.root}"/>
      <env key="PACKAGE_VERSION" value="0.1.0"/>

      <env key="PERMS" value="${perms}"/>
    </exec>
    <mkdir dir="${build.dir}"/>
    <mkdir dir="${build.dir}/test"/>
    <exec executable="cp" failonerror="true">
    <arg line="${root}/src/fuse_dfs ${build.dir}"/>
    </exec>
    <mkdir dir="${build.dir}/test"/>
    <exec executable="cp" failonerror="true">
    <arg line="${root}/src/fuse_dfs_wrapper.sh ${build.dir}"/>
    </exec>

  </target>

  <!-- override jar target !-->
  <target name="jar"/>

  <!-- override package target !-->
  <target name="package" depends="check-libhdfs-fuse" if="libhdfs-fuse">
    <echo message="contrib: ${name}"/>

    <mkdir dir="${dist.dir}/contrib/${name}"/>
    <exec executable="cp">
      <arg value="-p"/>
      <arg value="README"/>
      <arg value="src/fuse_dfs"/>
      <arg value="src/fuse_dfs_wrapper.sh"/>
      <arg value="${dist.dir}/contrib/${name}"/>
    </exec>
  </target>

  <target name="test" if="fusedfs">
    <echo message="testing FuseDFS ..."/>
   <antcall target="hadoopbuildcontrib.test"> 
   </antcall>
  </target>  

  <!-- override clean target !-->
  <target name="clean" depends="check-libhdfs-fuse" if="libhdfs-fuse">
    <echo message="contrib: ${name}"/>

    <exec executable="make">
      <arg value="clean"/>
    </exec>
  </target>

</project>
<?xml version="1.0" ?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="gridmix" default="jar">

  <import file="../build-contrib.xml"/>

</project>
<?xml version="1.0" ?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="hdfsproxy" default="jar">
	<property name="hdfsproxyVersion" value="1.0"/>
	<property name="final.name" value="${ant.project.name}-${hdfsproxyVersion}"/>
	<property name="bin.dir" value="${basedir}/bin"/>
	<property name="lib.dir" value="${basedir}/lib"/>
	<property name="conf.dir" value="${basedir}/conf"/>
	<property name="docs.dir" value="${basedir}/docs"/>
	<import file="../build-contrib.xml"/>

	<target name="jar" depends="compile" description="Create jar">
		<echo>
            Building the .jar files.
        </echo>
		<jar jarfile="${build.dir}/${final.name}.jar" basedir="${build.classes}" includes="org/apache/hadoop/hdfsproxy/**/*.class" >
                        <manifest>
                            <section name="org/apache/hadoop/hdfsproxy">
                                <attribute name="Implementation-Title" value="HdfsProxy"/>
                                <attribute name="Implementation-Version" value="${hdfsproxyVersion}"/>
                                <attribute name="Implementation-Vendor" value="Apache"/>
                            </section>
                        </manifest>

		</jar>
	</target>

	<!-- ====================================================== -->
	<!-- Macro definitions                                      -->
	<!-- ====================================================== -->
	<macrodef name="macro_tar" description="Worker Macro for tar">
		<attribute name="param.destfile"/>
		<element name="param.listofitems"/>
		<sequential>
			<tar compression="gzip" longfile="gnu"
          destfile="@{param.destfile}">
				<param.listofitems/>
			</tar>
		</sequential>
	</macrodef>

	<!-- ================================================================== -->
	<!-- D I S T R I B U T I O N                                            -->
	<!-- ================================================================== -->
	<!--                                                                    -->
	<!-- ================================================================== -->
	<target name="local-package" depends="jar" description="Package in local build directory">
		<mkdir dir="${build.dir}/${final.name}"/>
		<mkdir dir="${build.dir}/${final.name}/logs"/>
		<copy todir="${build.dir}/${final.name}" includeEmptyDirs="false">
			<fileset dir="${build.dir}">
				<include name="*.jar" />
				<include name="*.war" />
			</fileset>
		</copy>
		<copy todir="${build.dir}/${final.name}/lib" includeEmptyDirs="false">
			<fileset dir="${common.ivy.lib.dir}">
        <include name="commons-logging-${commons-logging.version}"/>
        <include name="commons-logging-api-${commons-logging-api.version}.jar"/>
        <include name="junit-${junit.version}.jar"/>
        <include name="log4j-${log4j.version}.jar"/>
        <include name="slf4j-api-${slf4j-api.version}.jar"/>
        <include name="slf4j-log4j${slf4j-log4j.version}.jar"/>
        <include name="xmlenc-${xmlenc.version}.jar"/>
        <include name="jetty-${jetty.version}.jar"/>
        <include name="servlet-api-${servlet-api-2.5.version}.jar"/>
        <include name="core-${core.vesion}"/> 
                       </fileset>
		       <fileset dir="${hadoop.root}/lib/jsp-${jsp.version}">
        <include name="jsp-${jsp.version}"/> 
        <include name="jsp-api-${jsp-api.vesion}"/> 
			</fileset>
		</copy>

		<copy todir="${build.dir}/${final.name}/lib" includeEmptyDirs="false">
                  	<fileset dir="${hadoop.root}/build">
                          	<include name="*-core.jar"/>
                          	<include name="*-tools.jar"/>
			</fileset>
		</copy>

		<copy todir="${build.dir}/${final.name}/bin">
			<fileset dir="${bin.dir}"/>
		</copy>

		<copy todir="${build.dir}/${final.name}/conf">
			<fileset dir="${conf.dir}"/>
		</copy>

		<copy todir="${build.dir}/${final.name}">
			<fileset dir="${basedir}">
				<include name="README" />
				<include name="build.xml" />
				<include name="*.txt" />
			</fileset>
		</copy>

		<copy todir="${build.dir}/${final.name}/src" includeEmptyDirs="true">
			<fileset dir="${src.dir}" excludes="**/*.template **/docs/build/**/*"/>
		</copy>

		<chmod perm="ugo+x" type="file" parallel="false">
			<fileset dir="${build.dir}/${final.name}/bin"/>
		</chmod>

	</target>
	
	<target name="package" depends="local-package" description="Build distribution">
    <mkdir dir="${dist.dir}/contrib/${name}"/>
    <copy todir="${dist.dir}/contrib/${name}">
      <fileset dir="${build.dir}/${final.name}">
      	<exclude name="**/lib/**" />
      	<exclude name="**/src/**" />
      </fileset>
    </copy>
    <chmod dir="${dist.dir}/contrib/${name}/bin" perm="a+x" includes="*"/>                
	</target>

	<!-- ================================================================== -->
	<!-- Make release tarball                                               -->
	<!-- ================================================================== -->
	<target name="tar" depends="local-package" description="Make release tarball">
		<macro_tar param.destfile="${build.dir}/${final.name}.tar.gz">
			<param.listofitems>
				<tarfileset dir="${build.dir}" mode="664">
					<exclude name="${final.name}/bin/*" />
					<include name="${final.name}/**" />
				</tarfileset>
				<tarfileset dir="${build.dir}" mode="755">
					<include name="${final.name}/bin/*" />
				</tarfileset>
			</param.listofitems>
		</macro_tar>
	</target>

	<target name="binary" depends="local-package" description="Make tarball without source and documentation">
		<macro_tar param.destfile="${build.dir}/${final.name}-bin.tar.gz">
			<param.listofitems>
				<tarfileset dir="${build.dir}" mode="664">
					<exclude name="${final.name}/bin/*" />
					<exclude name="${final.name}/src/**" />
					<exclude name="${final.name}/docs/**" />
					<include name="${final.name}/**" />
				</tarfileset>
				<tarfileset dir="${build.dir}" mode="755">
					<include name="${final.name}/bin/*" />
				</tarfileset>
			</param.listofitems>
		</macro_tar>
	</target>

  <!-- the unit test classpath -->
  <path id="test.classpath">
    <pathelement location="${build.test}" />
    <pathelement location="${hadoop.root}/build/test/classes"/>
    <pathelement location="${hadoop.root}/src/contrib/test"/>
    <pathelement location="${hadoop.root}/conf"/>
    <pathelement location="${hadoop.root}/build"/>
    <pathelement location="${hadoop.root}/build/classes"/>
    <pathelement location="${hadoop.root}/build/tools"/>
    <pathelement location="${build.examples}"/>
    <path refid="contrib-classpath"/>
  </path>


</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="highavailability" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

  <!-- ================================================================== -->
  <!-- Make hadoop-test.jar                                               -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar-test" depends="jar" description="Make hadoop-test.jar">
    <jar jarfile="${build.dir}/highavailability-test.jar"
         basedir="${build.test}">
    </jar>
  </target>


</project>

<?xml version="1.0"?>

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="hive-streaming" default="jar">

  <import file="../build-contrib.xml"/>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile">
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"      
    >
  	<manifest>
	    <attribute name="Main-Class" value="org.apache.hadoop.streaming.HadoopStreaming"/>
	</manifest>
    </jar>
  </target>

  <!-- Run only pure-Java unit tests. superdottest -->
  <target name="test">
   <antcall target="hadoopbuildcontrib.test"> 
     <param name="test.exclude" value="TestStreamedMerge"/>
   </antcall>
  </target>  
 
  <!-- Run all unit tests
  This is not called as part of the nightly build
  because it will only run on platforms that have standard 
  Unix utilities available. 
  -->
 <target name="test-unix">
   <antcall target="hadoopbuildcontrib.test">
   </antcall>
 </target>  


</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="hmon" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

  <target name="test" depends="compile,compile-test,test-junit" description="Automated Test Framework" if="test.available"/>

  <target name="test-junit" depends="compile,compile-test" if="test.available">
    <junit fork="yes" printsummary="yes" errorProperty="tests.failed" 
           haltonfailure="no" failureProperty="tests.failed">

        <classpath refid="test.classpath"/>
        <sysproperty key="test.build.data" value="${build.test}/data"/>
              <sysproperty key="build.test" value="${build.test}"/>
              <sysproperty key="user.dir" value="${build.test}/data"/>
              <sysproperty key="fs.default.name" value="${fs.default.name}"/>
              <sysproperty key="hadoop.test.localoutputfile" value="${hadoop.test.localoutputfile}"/>
              <sysproperty key="hadoop.log.dir" value="${hadoop.log.dir}"/>
        <sysproperty key="test.src.dir" value="${test.src.dir}"/>
        <formatter type="plain" />
        <batchtest todir="${build.test}" unless="testcase">
           <fileset dir="${src.test}">
             <include name="**/Test*.java"/>
           </fileset>
        </batchtest>
        <batchtest todir="${build.test}" if="testcase">
            <fileset dir="${src.test}">
                <include name="**/${testcase}.java"/>
            </fileset>
         </batchtest>
    </junit>
    <fail if="tests.failed">Tests failed!</fail>
 </target>

</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="hod" default="compile">
    <import file="../build-contrib.xml"/>
    <target name="compile">
        <mkdir dir="${build.dir}"/>
        <copy todir="${build.dir}">
            <fileset dir="${basedir}">
                <exclude name="**/VERSION"/>
            </fileset>
        </copy>
        <exec executable="echo" output="${build.dir}/bin/VERSION">
            <arg line="${version}" />
        </exec>
    </target>
    <target name="package" depends="compile">
        <mkdir dir="${dist.dir}/contrib/${name}"/>
        <copy todir="${dist.dir}/contrib/${name}">
            <fileset dir="${build.dir}"/>
        </copy>
        <chmod dir="${dist.dir}/contrib/${name}/bin" perm="a+x" includes="*"/>
    </target>

    <target name="test" depends="compile" description="Run HOD unit tests">  
      <antcall target="python.pathcheck"/>
      <antcall target="checkAndRunTests"/>
    </target>

    <target name="checkAndRunTests" if="python.home">
      <!-- Check python version now -->
      <exec executable="/bin/sh" outputproperty="hodtest.pythonVersion">
          <arg value="-c" />
          <arg value="${python.home}/python -V" />
      </exec>
      <condition property="python.versionmatched">
        <!--- Currently check for only 2.5.1 -->
        <equals arg1="${hodtest.pythonVersion}" arg2="Python 2.5.1" />
      </condition>
      <antcall target="python.versioncheck"/>
      <antcall target="runtests"/>
    </target>
 
    <target name="python.pathcheck" unless="python.home">
      <echo message="'python.home' is not defined. Please pass -Dpython.home=&lt;Path to Python&gt; to Ant on the command-line."/>
    </target>

    <target name="runtests" if="python.versionmatched">
      <echo message="Using Python at : ${python.home}" />
      <echo message="Version : ${hodtest.pythonVersion}"/>
      <exec executable="/bin/sh" resultproperty="hodtest.failedTests">
        <arg value="-c" />
          <arg value="${python.home}/python ${build.dir}/testing/main.py" />
      </exec>
      <condition property="hodtest.success">
        <equals arg1="${hodtest.failedTests}" arg2="0"/>
      </condition>
      <fail message="TestCases failed. ${hodtest.failedTests} failed to run successfully." unless="hodtest.success"/>
    </target>
    
    <target name="python.versioncheck" unless="python.versionmatched">
      <echo message="Need Python version 2.5.1. You specified ${hodtest.pythonVersion}"/>
    </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="index" default="jar">

  <import file="../build-contrib.xml"/>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"
    >
      <manifest>
        <attribute name="Main-Class" value="org.apache.hadoop.contrib.index.main.UpdateIndex"/>
      </manifest>
    </jar>
  </target>

  <!-- Override test target to copy sample data -->
  <target name="test" depends="compile-test, compile, compile-examples" if="test.available">
    <echo message="contrib: ${name}"/>
    <delete dir="${hadoop.log.dir}"/>
    <mkdir dir="${hadoop.log.dir}"/>
    <delete dir="${build.test}/sample"/>
    <mkdir dir="${build.test}/sample"/>
    <copy todir="${build.test}/sample">
      <fileset dir="${root}/sample"/>
    </copy>
    <junit
      printsummary="yes" showoutput="${test.output}" 
      haltonfailure="no" fork="yes" maxmemory="256m"
      errorProperty="tests.failed" failureProperty="tests.failed"
      timeout="${test.timeout}">
      
      <sysproperty key="test.build.data" value="${build.test}/data"/>
      <sysproperty key="build.test" value="${build.test}"/>
      <sysproperty key="contrib.name" value="${name}"/>
      
      <!-- requires fork=yes for: 
        relative File paths to use the specified user.dir 
        classpath to use build/contrib/*.jar
      -->
      <sysproperty key="user.dir" value="${build.test}/data"/>
      
      <sysproperty key="fs.default.name" value="${fs.default.name}"/>
      <sysproperty key="hadoop.test.localoutputfile" value="${hadoop.test.localoutputfile}"/>
      <sysproperty key="hadoop.log.dir" value="${hadoop.log.dir}"/>
      <classpath refid="test.classpath"/>
      <formatter type="${test.junit.output.format}" />
      <batchtest todir="${build.test}" unless="testcase">
        <fileset dir="${src.test}"
                 includes="**/Test*.java" excludes="**/${test.exclude}.java" />
      </batchtest>
      <batchtest todir="${build.test}" if="testcase">
        <fileset dir="${src.test}" includes="**/${testcase}.java"/>
      </batchtest>
    </junit>
    <fail if="tests.failed">Tests failed!</fail>

  </target>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="mumak" default="jar">

  <import file="../build-contrib.xml"/>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="namespace-notifier" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

  <target name="buildha">
    <subant target="jar-test">
      <fileset dir="../" includes="highavailability/build.xml" excludes=""/>
    </subant>
  </target>

  <target name="copy.libs">
    <mkdir dir="${build.dir}/lib"/>
    <copy todir="${build.dir}/lib">
      <!-- Copies the libthrift jar -->
      <fileset dir="${src.dir}/../../lib"/>
    </copy>
  </target>

  <target name="compile" depends="init, ivy-retrieve-common, copy.libs, buildha" unless="skip.contrib">
    <echo message="contrib: ${name}" />
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.dir}:${root}/gen-java"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
      <classpath refid="contrib-classpath"/>
      <classpath path="${hadoop.root}/build/contrib/highavailability/hadoop-${version}-highavailability.jar"/>
      <classpath path="${hadoop.root}/build/contrib/highavailability/highavailability-test.jar"/>
    </javac>
    <copy todir="${build.classes}">
       <fileset dir="${root}/conf">
         <include name="namespace-notifier-server-default.xml" />
       </fileset>
    </copy>
  </target>

  <!-- ================================================================== -->
  <!-- Compile test code                                                  -->
  <!-- ================================================================== -->
  <target name="compile-test" depends="compile-examples" if="test.available">
    <echo message="contrib: ${name}"/>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.test}"
     includes="**/*.java"
     destdir="${build.test}"
     debug="${javac.debug}">
      <classpath refid="test.classpath"/>
      <classpath path="${hadoop.root}/build/contrib/highavailability/hadoop-${version}-highavailability.jar"/>
      <classpath path="${hadoop.root}/build/contrib/highavailability/highavailability-test.jar"/>
    </javac>
  </target>
  
  <!-- ================================================================== -->
  <!-- Run unit tests                                                     -->
  <!-- ================================================================== -->
  <target name="test" depends="compile-test, compile" if="test.available">
    <echo message="contrib: ${name}"/>
    <delete dir="${hadoop.log.dir}"/>
    <mkdir dir="${hadoop.log.dir}"/>

    <emma enabled="${emma.enabled}">
      <instr instrpath="${build.classes}"
             destdir="${emma.instr.dir}"
             metadatafile="${emma.coverage.dir}/metadata.emma"
             merge="true"/>
    </emma>

    <junit
      printsummary="yes" showoutput="${test.output}"
      haltonfailure="no" fork="yes" 
      errorProperty="tests.failed" failureProperty="tests.failed"
      timeout="${test.timeout}"
      maxmemory="${test.junit.maxmemory}">

      <sysproperty key="test.build.data" value="${build.test}/data"/>
      <sysproperty key="build.test" value="${build.test}"/>
      <sysproperty key="contrib.name" value="${name}"/>

      <jvmarg value="-Demma.coverage.out.file=${emma.coverage.dir}/coverage.emma"/>

      <!-- requires fork=yes for:
        relative File paths to use the specified user.dir
        classpath to use build/contrib/*.jar
      -->
      <sysproperty key="user.dir" value="${build.test}/data"/>

      <sysproperty key="fs.default.name" value="${fs.default.name}"/>
      <sysproperty key="hadoop.test.localoutputfile" value="${hadoop.test.localoutputfile}"/>
      <sysproperty key="hadoop.log.dir" value="${hadoop.log.dir}"/>
      <sysproperty key="taskcontroller-path" value="${taskcontroller-path}"/>
      <sysproperty key="taskcontroller-user" value="${taskcontroller-user}"/>
      <classpath>
        <pathelement location="${emma.instr.dir}" />
        <path refid="test.classpath" />
        <path refid="emma.lib" />
      </classpath>
      <classpath path="${hadoop.root}/build/contrib/highavailability/hadoop-${version}-highavailability.jar"/>
      <classpath path="${hadoop.root}/build/contrib/highavailability/highavailability-test.jar"/>
      <formatter type="${test.junit.output.format}" />
      <batchtest todir="${build.test}" unless="testcase">
        <fileset dir="${src.test}"
          includes="**/${test.include}.java" excludes="**/${test.exclude}.java" />
      </batchtest>
      <batchtest todir="${build.test}" if="testcase">
        <fileset dir="${src.test}" includes="**/${testcase}.java"/>
      </batchtest>
    </junit>

    <emma enabled="${emma.enabled}">
      <report sourcepath="${src.dir}" >
        <fileset dir="${emma.coverage.dir}">
          <include name="*.emma" />
        </fileset>
        <txt outfile="${emma.coverage.dir}/coverage.txt"/>
        <html outfile="${emma.coverage.dir}/coverage.html"/>
      </report>
    </emma>

    <fail if="tests.failed">Tests failed!</fail>
  </target>


  <target name="package" depends="jar, jar-examples" unless="skip.contrib">
   <mkdir dir="${dist.dir}/contrib/${name}"/>
   <mkdir dir="${dist.dir}/contrib/${name}/conf"/>
   <copy todir="${dist.dir}/contrib/${name}">
    <fileset dir="${build.dir}">
       <include name="hadoop-${version}-${name}.jar" />
     </fileset>
   </copy>
   <copy todir="${dist.dir}/contrib/${name}/conf">
     <fileset dir="${root}/conf">
       <include name="namespace-notifier-server-site.xml" />
     </fileset>
   </copy>
   <copy todir="${dist.dir}/contrib/${name}">
     <fileset dir="${build.dir}">
       <include name="**/lib/"/>
     </fileset>
   </copy>
  </target>

</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="raid" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">
  <import file="../build-contrib.xml"/>

  <target name="buildha">
    <subant target="jar">
      <fileset dir="../" includes="highavailability/build.xml" excludes=""/>
    </subant>
  </target>

  <property name="build.webapp" value="${build.dir}/webapps"/>
  <property name="build.base.webapp" value="${build.dir}/../../webapps"/>
  <property name="build.src" value="${build.dir}/src" />
  <property name="src.webapp.raid" value="${basedir}/webapps/raid"/>

  <target name="compile" depends="init, ivy-retrieve-common, buildha" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
       <classpath refid="test.classpath"/>
    </taskdef>
    <mkdir dir="${build.webapp}/raid/WEB-INF"/>
    <copy file="${src.webapp.raid}/index.html" todir="${build.webapp}/raid"/>
    <jsp-compile
     uriroot="${src.webapp.raid}"
     outputdir="${build.src}"
     package="org.apache.hadoop.mapred"
     webxml="${build.webapp}/raid/WEB-INF/web.xml">
    </jsp-compile>
    <javac
     includeantruntime="true"
     encoding="${build.encoding}"
     srcdir="${src.dir};${build.src}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
     <classpath path="${hadoop.root}/build/contrib/highavailability/hadoop-${version}-highavailability.jar"/>
    </javac>

    <copy todir="${build.classes}">
     <fileset dir="${src.dir}" includes="raid-default.xml"/>
    </copy>
    <copy todir="${build.base.webapp}">
     <fileset dir="${build.webapp}" includes="**"/>
    </copy>
  </target>

  <target name="test" depends="compile-test, compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <delete dir="${hadoop.log.dir}"/>
    <mkdir dir="${hadoop.log.dir}"/>

    <emma enabled="${emma.enabled}">
      <instr instrpath="${build.classes}"
             destdir="${emma.instr.dir}"
             metadatafile="${emma.coverage.dir}/metadata.emma"
             merge="true"/>
    </emma>
    
    <copy todir="${build.classes}">
     <fileset dir="${src.test}" includes="raid-site.xml"/>
    </copy>

    <junit
      printsummary="yes" showoutput="${test.output}"
      haltonfailure="no" fork="yes" 
      errorProperty="tests.failed" failureProperty="tests.failed"
      timeout="${test.timeout}"
      maxmemory="${test.junit.maxmemory}">

      <sysproperty key="test.build.data" value="${build.test}/data"/>
      <sysproperty key="build.test" value="${build.test}"/>
      <sysproperty key="contrib.name" value="${name}"/>

      <jvmarg value="-Demma.coverage.out.file=${emma.coverage.dir}/coverage.emma"/>

      <!-- requires fork=yes for:
        relative File paths to use the specified user.dir
        classpath to use build/contrib/*.jar
      -->
      <sysproperty key="user.dir" value="${build.test}/data"/>

      <sysproperty key="fs.default.name" value="${fs.default.name}"/>
      <sysproperty key="hadoop.test.localoutputfile" value="${hadoop.test.localoutputfile}"/>
      <sysproperty key="hadoop.log.dir" value="${hadoop.log.dir}"/>
      <sysproperty key="taskcontroller-path" value="${taskcontroller-path}"/>
      <sysproperty key="taskcontroller-user" value="${taskcontroller-user}"/>
      <classpath>
        <pathelement location="${emma.instr.dir}" />
        <pathelement location="${src.test}" />
        <path refid="test.classpath" />
        <path refid="emma.lib" />
      </classpath>
      <formatter type="${test.junit.output.format}" />
      <batchtest todir="${build.test}" unless="testcase">
        <fileset dir="${src.test}"
          includes="**/${test.include}.java" excludes="**/${test.exclude}.java" />
      </batchtest>
      <batchtest todir="${build.test}" if="testcase">
        <fileset dir="${src.test}" includes="**/${testcase}.java"/>
      </batchtest>
    </junit>

    <emma enabled="${emma.enabled}">
      <report sourcepath="${src.dir}" >
        <fileset dir="${emma.coverage.dir}">
          <include name="*.emma" />
        </fileset>
        <txt outfile="${emma.coverage.dir}/coverage.txt"/>
        <html outfile="${emma.coverage.dir}/coverage.html"/>
      </report>
    </emma>

    <fail if="tests.failed">Tests failed!</fail>
  </target>

  <target name="jar" depends="compile" unless="skip.contrib">
    <echo message="contrib: ${name}"/>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}">
      <zipfileset dir="${build.webapp}" prefix="webapps"/>
    </jar>
  </target>

  <target name="package" depends="jar, jar-examples" unless="skip.contrib">
    <mkdir dir="${dist.dir}/contrib/${name}"/>
    <copy todir="${dist.dir}/contrib/${name}" includeEmptyDirs="false" flatten="true">
      <fileset dir="${build.dir}">
        <include name="hadoop-${version}-${name}.jar" />
      </fileset>
    </copy>
    <copy todir="${dist.dir}/contrib/${name}">
      <fileset dir="${build.dir}">
        <include name="**/lib/"/>
      </fileset>
    </copy>
    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapp}"/>
    </copy>
  </target>

</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="seekablecompression" default="jar">

  <import file="../build-contrib.xml"/>

</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="snapshot" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">

  <import file="../build-contrib.xml"/>

</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="storageservice" default="jar" xmlns:ivy="antlib:org.apache.ivy.ant">
  <import file="../build-contrib.xml"/>
</project>

<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- 
Before you can run these subtargets directly, you need 
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="streaming" default="jar">
  <import file="../build-contrib.xml"/>

  <fileset id="lib.jars" dir="${root}" includes="lib/*.jar"
           excludes="lib/commons-cli-2.0-SNAPSHOT.jar" />

  <!-- the normal classpath -->
  <path id="contrib-classpath">
    <pathelement location="${build.classes}"/>
    <fileset refid="lib.jars"/>
    <pathelement location="${hadoop.root}/build/classes"/>
    <pathelement location="${hadoop.root}/build/tools"/>
    <fileset dir="${hadoop.root}/lib">
      <include name="**/*.jar" />
      <exclude name="**/commons-cli-2.0-SNAPSHOT.jar"/>
    </fileset>
    <path refid="${ant.project.name}.common-classpath"/>
  </path>

  <!-- the unit test classpath -->
  <path id="test.classpath">
    <pathelement location="${build.test}" />
    <pathelement location="${hadoop.root}/build/test/classes"/>
    <pathelement location="${hadoop.root}/src/contrib/test"/>
    <pathelement location="${conf.dir}"/>
    <pathelement location="${hadoop.root}/build"/>
    <pathelement location="${build.examples}"/>
    <pathelement location="${hadoop.root}/build/examples"/>
    <path refid="contrib-classpath"/>
  </path>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile">
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"      
    >
  	<manifest>
	    <attribute name="Main-Class" value="org.apache.hadoop.streaming.HadoopStreaming"/>
	</manifest>
    </jar>
  </target>

  <!-- Run only pure-Java unit tests. superdottest -->
  <target name="test">
   <antcall target="hadoopbuildcontrib.test"> 
     <param name="test.exclude" value="TestStreamedMerge"/>
   </antcall>
  </target>  
 
  <!-- Run all unit tests
  This is not called as part of the nightly build
  because it will only run on platforms that have standard 
  Unix utilities available. 
  -->
 <target name="test-unix">
   <antcall target="hadoopbuildcontrib.test">
   </antcall>
 </target>  


</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="thriftdatanode" default="jar">

  <import file="../build-contrib.xml"/>

  <!-- create the list of files to add to the classpath -->
  <fileset dir="${hadoop.root}/../thriftfs/lib" id="contrib.classpath">
    <include name="**/*.jar" />
    <exclude name="**/excluded/" />
  </fileset>

  <target name="thriftif">
    <echo>Executing thrift (which needs to be in your path) to build java hadoopfs APIs.... </echo>
    <exec executable="thrift"  failonerror="true" dir=".">
      <arg line="--gen java --gen py -o ${root} if/hadoopdatanode.thrift " />
    </exec>
  </target>

  <property name="gen.java.dir" value="${src.dir}/../../gen-java"/>

  <!-- Compiles thrift-generated java code. Should be run when thirft
       interface is changed. -->
  <target name="thriftjar" depends="thriftif, init, ivy-retrieve-common">
    <javac
     encoding="${build.encoding}"
     srcdir="${gen.java.dir}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
    </javac>
    <jar
      jarfile="${root}/lib/hadoopthriftdatanodeapi.jar"
      basedir="${build.classes}"
      includes="**/thriftdatanode/api/"
    />
  </target>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile, copy.libs">
    <echo>Building hadoop datanode thrift proxy ${build.dir}/hadoop-${version}-${name}.jar</echo>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"
    >
  	<manifest>
	    <attribute name="Main-Class" value="org.apache.hadoop.thriftdatanode.HadooopThriftDatanodeServer"/>
	</manifest>
    </jar>
  </target>

  <target name="copy.libs">
    <mkdir dir="${build.dir}/lib"/>
    <copy todir="${build.dir}/lib">
      <!-- Copies the libthrift jar and the thrift API jar -->
      <fileset dir="${src.dir}/../../lib"/>
      <!-- Copies the thrift definition. Useful as a lib reference -->
      <fileset dir="${src.dir}/../../if"/>
    </copy>
    <!-- Copies the thrift generated python libraries -->
    <mkdir dir="${build.dir}/lib/py"/>
    <copy todir="${build.dir}/lib/py">
      <fileset dir="${src.dir}/../../gen-py"/>
    </copy>

  </target>
</project>
<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!--
Before you can run these subtargets directly, you need
to call at top-level: ant deploy-contrib compile-core-test
-->
<project name="thriftfs" default="jar">

  <import file="../build-contrib.xml"/>

  <!-- create the list of files to add to the classpath -->
  <fileset dir="${hadoop.root}/lib" id="class.path">
    <include name="**/*.jar" />
    <exclude name="**/excluded/" />
  </fileset>

  <target name="thriftif">
    <echo>Executing thrift (which needs to be in your path) to build java hadoopfs APIs.... </echo>
    <exec executable="thrift"  failonerror="true" dir=".">
      <arg line="--gen java --gen py -o ${root} if/hadoopfs.thrift " />
    </exec>
  </target>

  <property name="gen.java.dir" value="${src.dir}/../../gen-java"/>

  <!-- Compiles thrift-generated java code. Should be run when thirft
       interface is changed. -->
  <target name="thriftjar" depends="thriftif, init, ivy-retrieve-common">
    <javac
     encoding="${build.encoding}"
     srcdir="${gen.java.dir}"
     includes="**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     deprecation="${javac.deprecation}">
     <classpath refid="contrib-classpath"/>
    </javac>
    <jar
      jarfile="${root}/lib/hadoopthriftapi.jar"
      basedir="${build.classes}"
      includes="**/thriftfs/api/"
    />
  </target>

  <!-- Override jar target to specify main class -->
  <target name="jar" depends="compile, copy.libs">
    <echo>Building hadoop thrift proxy ${build.dir}/hadoop-${version}-${name}.jar</echo>
    <jar
      jarfile="${build.dir}/hadoop-${version}-${name}.jar"
      basedir="${build.classes}"
    >
  	<manifest>
	    <attribute name="Main-Class" value="org.apache.hadoop.thriftfs.HadooopThriftServer"/>
	</manifest>
    </jar>
  </target>

  <target name="copy.libs">
    <mkdir dir="${build.dir}/lib"/>
    <copy todir="${build.dir}/lib">
      <!-- Copies the libthrift jar and the thrift API jar -->
      <fileset dir="${src.dir}/../../lib"/>
      <!-- Copies the thrift definition. Useful as a lib reference -->
      <fileset dir="${src.dir}/../../if"/>
    </copy>
    <!-- Copies the thrift generated python libraries -->
    <mkdir dir="${build.dir}/lib/py"/>
    <copy todir="${build.dir}/lib/py">
      <fileset dir="${src.dir}/../../gen-py"/>
    </copy>

  </target>
</project>
<?xml version="1.0" ?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="vaidya" default="jar">

	<import file="../build-contrib.xml" />
        <import file="../../../build.xml" />

	<target name="init">
		<mkdir dir="${build.dir}" />
		<mkdir dir="${build.classes}" />
		<mkdir dir="${build.dir}/bin" />
		<mkdir dir="${build.dir}/conf" />

		<copy todir="${build.dir}/bin">
			<!-- copy hadoop vaidya command script file to hadoop-vaidya/bin -->
			<fileset dir="${basedir}/src/java/org/apache/hadoop/vaidya">
				<include name="vaidya.sh" />
			</fileset>
		</copy>

		<copy todir="${build.dir}/conf">
			<!-- copy hadoop vaidya tests config file to chuckwa/conf -->
			<fileset dir="${basedir}/src/java/org/apache/hadoop/vaidya/postexdiagnosis/tests">
				<include name="postex_diagnosis_tests.xml" />
			</fileset>
		</copy>
	</target>

	<!-- ====================================================== -->
	<!-- Override jar target to include the tests conf xml file -->
	<!-- ====================================================== -->
	<target name="jar" depends="compile" unless="skip.contrib">
		<echo message="contrib: ${name}" />
		<jar jarfile="${build.dir}/hadoop-${version}-${name}.jar">
			<fileset dir="${build.classes}" />
			<fileset dir="${basedir}/src/java/org/apache/hadoop/vaidya/postexdiagnosis/tests">
				<include name="postex_diagnosis_tests.xml" />
			</fileset>
		</jar>
	</target>

	<target name="package" depends="jar">
		<mkdir dir="${dist.dir}/contrib/${name}" />
		<copy todir="${dist.dir}/contrib/${name}" includeEmptyDirs="false">
			<fileset dir="${build.dir}">
				<exclude name="**/classes/" />
			</fileset>
		</copy>
		<chmod dir="${dist.dir}/contrib/${name}/bin" perm="a+x" includes="*" />
	</target>

</project>
